{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Plot Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_instance_complexity_histogram(results, title):\n",
    "    # Define Instance Complexity ranges\n",
    "    results_105 = results[(results['Instance Complexity'] >= 1.05) & (results['Instance Complexity'] < 1.1)]\n",
    "    results_110 = results[(results['Instance Complexity'] >= 1.1) & (results['Instance Complexity'] < 1.25)]\n",
    "    results_115 = results[(results['Instance Complexity'] >= 1.25) & (results['Instance Complexity'] < 1.5)]\n",
    "    results_high = results[(results['Instance Complexity'] >= 1.5) & (results['Instance Complexity'] < 2)]\n",
    "    results_higher = results[results['Instance Complexity'] >= 2]\n",
    "    labels = ['1.05-1.1', '1.1-1.25', '1.25-1.5', '1.5-2.0', '>= 2.0']\n",
    "    counts = [len(results_105), len(results_110), len(results_115), len(results_high), len(results_higher)]\n",
    "    fig, ax = plt.subplots(figsize=(8, 4))\n",
    "    bars = ax.bar(labels, counts, color='lightgreen', edgecolor='black')\n",
    "    ax.set_xlabel('Instance Complexity', fontsize=14, fontweight='bold')\n",
    "    ax.set_ylabel('Count', fontsize=14, fontweight='bold')\n",
    "    ax.set_title(title, fontsize=18, fontweight='bold')\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    return plt\n",
    "    plt.show()\n",
    "\n",
    "results32_on_32 = pd.read_csv('no_w_32_espoir_out_of_distrib_NON_resized.csv')\n",
    "plot = plot_instance_complexity_histogram(results32_on_32, 'Instance Complexity Histogram of the o-o-d dataset')\n",
    "plot.savefig('instance_complexity_histogram_ood.pdf', bbox_inches='tight', dpi=300)\n",
    "plot.show()\n",
    "\n",
    "def get_results_instance_complexity_more_than(results, threshold):\n",
    "    return results[results['Instance Complexity'] > threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_metric_divisor(results, metrics, title, ylabel, colors, divisor, yminlim, ymaxlim):\n",
    "    \"\"\"\n",
    "    Plot the metrics based on the Instance Complexity.\n",
    "\n",
    "    Parameters:\n",
    "        results: DataFrame containing the data.\n",
    "        metrics: List of metrics (strings) to be plotted.\n",
    "        title: Title of the plot.\n",
    "        ylabel: Label for the y-axis.\n",
    "        colors: List of colors for each metric's box plot.\n",
    "    \"\"\"\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 4))\n",
    "    \n",
    "    # Define Instance Complexity ranges\n",
    "    results_105 = results[(results['Instance Complexity'] >= 1.05) & (results['Instance Complexity'] < 1.1)]\n",
    "    results_110 = results[(results['Instance Complexity'] >= 1.1) & (results['Instance Complexity'] < 1.25)]\n",
    "    results_115 = results[(results['Instance Complexity'] >= 1.25) & (results['Instance Complexity'] < 1.5)]\n",
    "    results_high = results[(results['Instance Complexity'] >= 1.5) & (results['Instance Complexity'] < 2)]\n",
    "    results_higher = results[results['Instance Complexity'] >= 2]\n",
    "    \n",
    "    labels = ['1.05-1.1', '1.1-1.25', '1.25-1.5', '1.5-2.0', '>= 2.0']\n",
    "    \n",
    "    # Prepare data for each metric\n",
    "    data = []\n",
    "    for metric in metrics:\n",
    "        if divisor is not None:\n",
    "            data.append([\n",
    "                100 * results_105[metric] / results_105[divisor],\n",
    "                100 * results_110[metric] / results_110[divisor],\n",
    "                100 * results_115[metric] / results_115[divisor],\n",
    "                100 * results_high[metric] / results_high[divisor],\n",
    "                100 * results_higher[metric] / results_higher[divisor]\n",
    "            ])\n",
    "        else:\n",
    "            data.append([\n",
    "                results_105[metric], \n",
    "                results_110[metric], \n",
    "                results_115[metric], \n",
    "                results_high[metric], \n",
    "                results_higher[metric]\n",
    "            ])\n",
    "\n",
    "    # Plot each metric's boxplot with different colors\n",
    "    num_metrics = len(metrics)\n",
    "    positions = np.arange(len(labels)) * (num_metrics + 2)\n",
    "    \n",
    "    for i, metric_data in enumerate(data):\n",
    "        bplot = ax.boxplot(\n",
    "            metric_data, \n",
    "            positions=positions + i * 0.9 - 0.1, \n",
    "            widths=0.6, \n",
    "            patch_artist=True, \n",
    "            meanline=True, \n",
    "            showfliers=False, \n",
    "            notch=True, \n",
    "            autorange=True, \n",
    "            showmeans=True, \n",
    "            meanprops=dict(marker='', color='r'), \n",
    "            medianprops=dict(color='k')\n",
    "        )\n",
    "        for patch in bplot['boxes']:\n",
    "            patch.set_facecolor(colors[i])\n",
    "    \n",
    "    # Set x-axis labels and positions\n",
    "    ax.set_xticks(positions + (num_metrics / 2) - 1)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.set_xlabel('Instance Complexity', fontsize=14, fontweight='bold')\n",
    "    ax.set_ylabel(ylabel, fontsize=14, fontweight='bold')\n",
    "    \n",
    "    #use ymaxlim to set the y-axis limit\n",
    "    if ymaxlim is not None:\n",
    "        ax.set_ylim(yminlim, ymaxlim)\n",
    "    \n",
    "    # use mtick.PercentFormatter(xmax=1) to set the y-axis as percentage\n",
    "    \n",
    "    # Add title and legend\n",
    "    plt.title(title + ' depending on the Instance Complexity', fontsize=18, fontweight='bold')\n",
    "    plt.legend([plt.Rectangle((0,0),1,1,fc=colors[i], ec='k') for i in range(num_metrics)], \n",
    "               [metric.split(\" \")[-1] for metric in metrics], \n",
    "               loc='best')\n",
    "\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    return plt\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_metric_divisor_map(results, metrics, title, ylabel, colors, divisor, yminlim, ymaxlim):\n",
    "    \"\"\"\n",
    "    Plot the metrics based on the Type of map.\n",
    "\n",
    "    Parameters:\n",
    "        results: DataFrame containing the data.\n",
    "        metrics: List of metrics (strings) to be plotted.\n",
    "        title: Title of the plot.\n",
    "        ylabel: Label for the y-axis.\n",
    "        colors: List of colors for each metric's box plot.\n",
    "    \"\"\"\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 4))\n",
    "    \n",
    "    # get type of map from the results unique\n",
    "    type_of_map = results['Type of map'].unique()\n",
    "    \n",
    "    # Define Instance Complexity ranges\n",
    "    results_1 = results[results['Type of map'] == type_of_map[0]]\n",
    "    results_2 = results[results['Type of map'] == type_of_map[1]]\n",
    "    results_3 = results[results['Type of map'] == type_of_map[2]]\n",
    "    results_4 = results[results['Type of map'] == type_of_map[3]]\n",
    "    results_5 = results[results['Type of map'] == type_of_map[4]]\n",
    "    results_6 = results[results['Type of map'] == type_of_map[5]]\n",
    "    results_7 = results[results['Type of map'] == type_of_map[6]]\n",
    "    results_8 = results[results['Type of map'] == type_of_map[7]]\n",
    "    \n",
    "    labels = [type_of_map[0], type_of_map[1], type_of_map[2], type_of_map[3], type_of_map[4], type_of_map[5], type_of_map[6], type_of_map[7]]\n",
    "    \n",
    "    # Prepare data for each metric\n",
    "    data = []\n",
    "    for metric in metrics:\n",
    "        if divisor is not None:\n",
    "            data.append([\n",
    "                100 * results_1[metric] / results_1[divisor],\n",
    "                100 * results_2[metric] / results_2[divisor],\n",
    "                100 * results_3[metric] / results_3[divisor],\n",
    "                100 * results_4[metric] / results_4[divisor],\n",
    "                100 * results_5[metric] / results_5[divisor],\n",
    "                100 * results_6[metric] / results_6[divisor],\n",
    "                100 * results_7[metric] / results_7[divisor],\n",
    "                100 * results_8[metric] / results_8[divisor]\n",
    "            ])\n",
    "        else:\n",
    "            data.append([\n",
    "                results_1[metric], \n",
    "                results_2[metric], \n",
    "                results_3[metric], \n",
    "                results_4[metric], \n",
    "                results_5[metric], \n",
    "                results_6[metric], \n",
    "                results_7[metric], \n",
    "                results_8[metric]\n",
    "            ])\n",
    "        \n",
    "    # Plot each metric's boxplot with different colors\n",
    "    num_metrics = len(metrics)\n",
    "    positions = np.arange(len(labels)) * (num_metrics + 2)\n",
    "\n",
    "    # Plot each metric's boxplot with different colors\n",
    "    for i, metric_data in enumerate(data):\n",
    "        bplot = ax.boxplot(\n",
    "            metric_data, \n",
    "            positions=positions + i * 0.9 - 0.1, \n",
    "            widths=0.6, \n",
    "            patch_artist=True, \n",
    "            meanline=True, \n",
    "            showfliers=False, \n",
    "            notch=True, \n",
    "            autorange=True, \n",
    "            showmeans=True, \n",
    "            meanprops=dict(marker='', color='r'), \n",
    "            medianprops=dict(color='k')\n",
    "        )\n",
    "        \n",
    "        for patch in bplot['boxes']:\n",
    "            patch.set_facecolor(colors[i])\n",
    "            \n",
    "    # Set x-axis labels and positions\n",
    "    ax.set_xticks(positions + (num_metrics / 2) - 1)\n",
    "    \n",
    "    \n",
    "    #use ymaxlim to set the y-axis limit\n",
    "    if ymaxlim is not None:\n",
    "        ax.set_ylim(yminlim, ymaxlim)\n",
    "    \n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.set_xlabel('Type of map', fontsize=14, fontweight='bold')\n",
    "    ax.set_ylabel(ylabel, fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Add title and legend\n",
    "    plt.title(title + ' depending on the Type of map', fontsize=18, fontweight='bold')\n",
    "    plt.legend([plt.Rectangle((0,0),1,1,fc=colors[i], ec='k') for i in range(len(metrics))], [metric.split(\" \")[-1] for metric in metrics], loc='best')\n",
    "    \n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    return plt\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# same with size\n",
    "def plot_metric_divisor_size(results, metrics, title, ylabel, colors, divisor, yminlim, ymaxlim):\n",
    "    \"\"\"\n",
    "    Plot the metrics based on the Type of map.\n",
    "\n",
    "    Parameters:\n",
    "        results: DataFrame containing the data.\n",
    "        metrics: List of metrics (strings) to be plotted.\n",
    "        title: Title of the plot.\n",
    "        ylabel: Label for the y-axis.\n",
    "        colors: List of colors for each metric's box plot.\n",
    "    \"\"\"\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 4))\n",
    "    \n",
    "    # get type of map from the results unique\n",
    "    if results['Size'].dtype == 'int64':\n",
    "        size = [32, 64, 96, 128, 256]\n",
    "    else:\n",
    "        size = ['32x32', '64x64', '96x96', '128x128', '256x256']\n",
    "    \n",
    "    # Define Instance Complexity ranges\n",
    "    results_1 = results[results['Size'] == size[0]]\n",
    "    results_2 = results[results['Size'] == size[1]]\n",
    "    results_3 = results[results['Size'] == size[2]]\n",
    "    results_4 = results[results['Size'] == size[3]]\n",
    "    results_5 = results[results['Size'] == size[4]]\n",
    "    \n",
    "    labels = [size[0], size[1], size[2], size[3], size[4]]\n",
    "    if results['Size'].dtype == 'int64':\n",
    "        labels = [str(label)+'x'+str(label) for label in labels]\n",
    "    \n",
    "    # Prepare data for each metric\n",
    "    data = []\n",
    "    for metric in metrics:\n",
    "        if divisor is not None:\n",
    "            data.append([\n",
    "                100 * results_1[metric] / results_1[divisor],\n",
    "                100 * results_2[metric] / results_2[divisor],\n",
    "                100 * results_3[metric] / results_3[divisor],\n",
    "                100 * results_4[metric] / results_4[divisor],\n",
    "                100 * results_5[metric] / results_5[divisor]\n",
    "            ])\n",
    "        else:\n",
    "            data.append([\n",
    "                results_1[metric], \n",
    "                results_2[metric], \n",
    "                results_3[metric], \n",
    "                results_4[metric], \n",
    "                results_5[metric]\n",
    "            ])\n",
    "            \n",
    "    # Plot each metric's boxplot with different colors\n",
    "    num_metrics = len(metrics)\n",
    "    positions = np.arange(len(labels)) * (num_metrics + 2)\n",
    "    \n",
    "    for i, metric_data in enumerate(data):\n",
    "        bplot = ax.boxplot(\n",
    "            metric_data, \n",
    "            positions=positions + i * 0.9 - 0.1, \n",
    "            widths=0.6, \n",
    "            patch_artist=True, \n",
    "            meanline=True, \n",
    "            showfliers=False, \n",
    "            notch=True, \n",
    "            autorange=True, \n",
    "            showmeans=True, \n",
    "            meanprops=dict(marker='', color='r'), \n",
    "            medianprops=dict(color='k')\n",
    "        )\n",
    "        \n",
    "        for patch in bplot['boxes']:\n",
    "            patch.set_facecolor(colors[i])\n",
    "            \n",
    "            \n",
    "            \n",
    "    #use ymaxlim to set the y-axis limit\n",
    "    if ymaxlim is not None:\n",
    "        ax.set_ylim(yminlim, ymaxlim)\n",
    "        \n",
    "        \n",
    "    # Set x-axis labels and positions\n",
    "    ax.set_xticks(positions + (num_metrics / 2) - 1)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.set_xlabel('Size', fontsize=14, fontweight='bold')\n",
    "    ax.set_ylabel(ylabel, fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Add title and legend\n",
    "    plt.title(title + ' depending on the Size', fontsize=18, fontweight='bold')\n",
    "    plt.legend([plt.Rectangle((0,0),1,1,fc=colors[i], ec='k') for i in range(len(metrics))], [metric.split(\" \")[-1] for metric in metrics], loc='best')\n",
    "    \n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    return plt\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trained on MP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tested on MP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results32_on_32 = pd.read_csv('no_w_espoir_final_32.csv')\n",
    "\n",
    "plot_instance_complexity_histogram(results32_on_32, 'Instance complexity on 32x32 dataset')\n",
    "\n",
    "results32_on_32_more_than_1_05 = get_results_instance_complexity_more_than(results32_on_32, 1.05)\n",
    "\n",
    "plot_instance_complexity_histogram(results32_on_32_more_than_1_05, 'Instance complexity on 32x32 dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get statistics results32_on_32 describe but only if optimal found is in the column\n",
    "print(results32_on_32.filter(like='Optimal F').describe())\n",
    "print(results32_on_32_more_than_1_05.filter(like='Optimal F').describe())\n",
    "\n",
    "print(results32_on_32.filter(like='Path L').describe())\n",
    "print(results32_on_32_more_than_1_05.filter(like='Path L').describe())\n",
    "\n",
    "print(results32_on_32.filter(like='Exp').describe())\n",
    "print(results32_on_32_more_than_1_05.filter(like='Exp').describe())\n",
    "\n",
    "print(results32_on_32.filter(like='Run Time ').describe())\n",
    "print(results32_on_32_more_than_1_05.filter(like='Run Time ').describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_metric_divisor(results32_on_32, ['Optimal Found CF', 'Optimal Found CF+0.25*PPM', 'Optimal Found CF+0.50*PPM',\n",
    "#       'Optimal Found CF+0.75*PPM', 'Optimal Found CF+1*PPM', 'Optimal Found PPM+MAN', 'Optimal Found PPM+CF', 'Optimal Found CF/PPM'], 'Optimality Ratio', 'Optimality Ratio (%)', ['#FFD700', '#BFAC40', '#80AB80', '#408080', '#406ABF', '#007FFF', '#7F547F', \"#FFFF00\"], None)\n",
    "\n",
    "plot_metric_divisor(results32_on_32, ['Predicted Path Length CF', 'Predicted Path Length CF+0.25*PPM', 'Predicted Path Length CF+0.50*PPM',\n",
    "       'Predicted Path Length CF+0.75*PPM', 'Predicted Path Length CF+1*PPM', 'Predicted Path Length PPM+MAN', 'Predicted Path Length PPM+CF', 'Predicted Path Length CF/PPM'], 'Path Length Ratio', 'Path Length Ratio (%)', ['#FFD700', '#BFAC40', '#80AB80', '#408080', '#406ABF', '#007FFF', '#7F547F', \"#FFFF00\"], 'Manhattan Path Length')\n",
    "\n",
    "plot_metric_divisor(results32_on_32, ['Predicted Path Length CF', 'Predicted Path Length CF+0.25*PPM', 'Predicted Path Length CF+0.50*PPM',\n",
    "       'Predicted Path Length CF+0.75*PPM', 'Predicted Path Length CF+1*PPM', 'Predicted Path Length PPM+MAN', 'Predicted Path Length PPM+CF', 'Predicted Path Length CF/PPM'], 'Path Length Ratio', 'Path Length Ratio (%)', ['#FFD700', '#BFAC40', '#80AB80', '#408080', '#406ABF', '#007FFF', '#7F547F', \"#FFFF00\"], 'Ground Truth Path Length')\n",
    "\n",
    "plot_metric_divisor(results32_on_32, ['Expansion CF', 'Expansion CF+0.25*PPM', 'Expansion CF+0.50*PPM',\n",
    "       'Expansion CF+0.75*PPM', 'Expansion CF+1*PPM', 'Expansion PPM+MAN', 'Expansion PPM+CF', 'Expansion CF/PPM'], 'Expansion Ratio', 'Expansion Ratio (%)', ['#FFD700', '#BFAC40', '#80AB80', '#408080', '#406ABF', '#007FFF', '#7F547F', \"#FFFF00\"], 'Expansion Manhattan')\n",
    "\n",
    "plot_metric_divisor(results32_on_32, ['Run Time CF', 'Run Time CF+0.25*PPM', 'Run Time CF+0.50*PPM',\n",
    "       'Run Time CF+0.75*PPM', 'Run Time CF+1*PPM', 'Run Time PPM+MAN', 'Run Time PPM+CF', 'Run Time CF/PPM'], 'Search Time Ratio', 'Search Time Ratio (%)', ['#FFD700', '#BFAC40', '#80AB80', '#408080', '#406ABF', '#007FFF', '#7F547F', \"#FFFF00\"], 'Run Time Manhattan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric_divisor_map(results32_on_32, ['Expansion CF', 'Expansion CF+0.25*PPM', 'Expansion CF+0.50*PPM',\n",
    "       'Expansion CF+0.75*PPM', 'Expansion CF+1*PPM', 'Expansion PPM+MAN', 'Expansion PPM+CF', 'Expansion CF/PPM'], 'Expansion Ratio', 'Expansion Ratio (%)', ['#FFD700', '#BFAC40', '#80AB80', '#408080', '#406ABF', '#007FFF', '#7F547F', \"#FFFF00\"], 'Expansion Manhattan')\n",
    "\n",
    "plot_metric_divisor_map(results32_on_32, ['Run Time CF', 'Run Time CF+0.25*PPM', 'Run Time CF+0.50*PPM',\n",
    "       'Run Time CF+0.75*PPM', 'Run Time CF+1*PPM', 'Run Time PPM+MAN', 'Run Time PPM+CF', 'Run Time CF/PPM'], 'Search Time Ratio', 'Search Time Ratio (%)', ['#FFD700', '#BFAC40', '#80AB80', '#408080', '#406ABF', '#007FFF', '#7F547F', \"#FFFF00\"], 'Run Time Manhattan')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tested on Tiled-MP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results32_on_resized = pd.read_csv('no_w_32_espoir_results_on_new_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results32_on_resized_more_than_1_05 = get_results_instance_complexity_more_than(results32_on_resized, 1.05)\n",
    "\n",
    "plot_instance_complexity_histogram(results32_on_resized, 'Instance complexity on resized dataset')\n",
    "\n",
    "plot_instance_complexity_histogram(results32_on_resized_more_than_1_05, 'Instance complexity on resized dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results32_on_resized.filter(like='Optimal F').describe())\n",
    "print(results32_on_resized_more_than_1_05.filter(like='Optimal F').describe())\n",
    "\n",
    "print(results32_on_resized.filter(like='Path L').describe())\n",
    "print(results32_on_resized_more_than_1_05.filter(like='Path L').describe())\n",
    "\n",
    "print(results32_on_resized.filter(like='Exp').describe())\n",
    "print(results32_on_resized_more_than_1_05.filter(like='Exp').describe())\n",
    "\n",
    "print(results32_on_resized.filter(like='Run Time ').describe())\n",
    "print(results32_on_resized_more_than_1_05.filter(like='Run Time ').describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric_divisor(results32_on_resized, ['Predicted Path Length CF', 'Predicted Path Length CF+0.25*PPM', 'Predicted Path Length CF+0.50*PPM',\n",
    "                                           'Predicted Path Length CF+0.75*PPM', 'Predicted Path Length CF+1*PPM', 'Predicted Path Length PPM+MAN', 'Predicted Path Length PPM+CF', 'Predicted Path Length CF/PPM'], 'Path Length Ratio', 'Path Length Ratio (%)', ['#FFD700', '#BFAC40', '#80AB80', '#408080', '#406ABF', '#007FFF', '#7F547F', \"#FFFF00\"], 'Manhattan Path Length')\n",
    "\n",
    "plot_metric_divisor(results32_on_resized, ['Predicted Path Length CF', 'Predicted Path Length CF+0.25*PPM', 'Predicted Path Length CF+0.50*PPM',\n",
    "                                           'Predicted Path Length CF+0.75*PPM', 'Predicted Path Length CF+1*PPM', 'Predicted Path Length PPM+MAN', 'Predicted Path Length PPM+CF', 'Predicted Path Length CF/PPM'], 'Path Length Ratio', 'Path Length Ratio (%)', ['#FFD700', '#BFAC40', '#80AB80', '#408080', '#406ABF', '#007FFF', '#7F547F', \"#FFFF00\"], 'Ground Truth Path Length')\n",
    "\n",
    "plot_metric_divisor(results32_on_resized, ['Expansion CF', 'Expansion CF+0.25*PPM', 'Expansion CF+0.50*PPM',\n",
    "       'Expansion CF+0.75*PPM', 'Expansion CF+1*PPM', 'Expansion PPM+MAN', 'Expansion PPM+CF', 'Expansion CF/PPM'], 'Expansion Ratio', 'Expansion Ratio (%)', ['#FFD700', '#BFAC40', '#80AB80', '#408080', '#406ABF', '#007FFF', '#7F547F', \"#FFFF00\"], 'Expansion Manhattan')\n",
    "\n",
    "plot_metric_divisor(results32_on_resized, ['Run Time CF', 'Run Time CF+0.25*PPM', 'Run Time CF+0.50*PPM', \n",
    "         'Run Time CF+0.75*PPM', 'Run Time CF+1*PPM', 'Run Time PPM+MAN', 'Run Time PPM+CF', 'Run Time CF/PPM'], 'Search Time Ratio', 'Search Time Ratio (%)', ['#FFD700', '#BFAC40', '#80AB80', '#408080', '#406ABF', '#007FFF', '#7F547F', \"#FFFF00\"], 'Run Time Manhattan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric_divisor_size(results32_on_resized, ['Predicted Path Length CF', 'Predicted Path Length CF+0.25*PPM', 'Predicted Path Length CF+0.50*PPM',\n",
    "                                           'Predicted Path Length CF+0.75*PPM', 'Predicted Path Length CF+1*PPM', 'Predicted Path Length PPM+MAN', 'Predicted Path Length PPM+CF', 'Predicted Path Length CF/PPM'], 'Path Length Ratio', 'Path Length Ratio (%)', ['#FFD700', '#BFAC40', '#80AB80', '#408080', '#406ABF', '#007FFF', '#7F547F', \"#FFFF00\"], 'Manhattan Path Length')\n",
    "\n",
    "plot_metric_divisor_size(results32_on_resized, ['Predicted Path Length CF', 'Predicted Path Length CF+0.25*PPM', 'Predicted Path Length CF+0.50*PPM',\n",
    "                                           'Predicted Path Length CF+0.75*PPM', 'Predicted Path Length CF+1*PPM', 'Predicted Path Length PPM+MAN', 'Predicted Path Length PPM+CF', 'Predicted Path Length CF/PPM'], 'Path Length Ratio', 'Path Length Ratio (%)', ['#FFD700', '#BFAC40', '#80AB80', '#408080', '#406ABF', '#007FFF', '#7F547F', \"#FFFF00\"], 'Ground Truth Path Length')\n",
    "\n",
    "plot_metric_divisor_size(results32_on_resized, ['Expansion CF', 'Expansion CF+0.25*PPM', 'Expansion CF+0.50*PPM',\n",
    "       'Expansion CF+0.75*PPM', 'Expansion CF+1*PPM', 'Expansion PPM+MAN', 'Expansion PPM+CF', 'Expansion CF/PPM'], 'Expansion Ratio', 'Expansion Ratio (%)', ['#FFD700', '#BFAC40', '#80AB80', '#408080', '#406ABF', '#007FFF', '#7F547F', \"#FFFF00\"], 'Expansion Manhattan')\n",
    "\n",
    "plot_metric_divisor_size(results32_on_resized, ['Run Time CF', 'Run Time CF+0.25*PPM', 'Run Time CF+0.50*PPM', \n",
    "         'Run Time CF+0.75*PPM', 'Run Time CF+1*PPM', 'Run Time PPM+MAN', 'Run Time PPM+CF', 'Run Time CF/PPM'], 'Search Time Ratio', 'Search Time Ratio (%)', ['#FFD700', '#BFAC40', '#80AB80', '#408080', '#406ABF', '#007FFF', '#7F547F', \"#FFFF00\"], 'Run Time Manhattan')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tested on ood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results32_on_oob = pd.read_csv('no_w_32_espoir_out_of_distrib_NON_resized.csv')\n",
    "\n",
    "plot_instance_complexity_histogram(results32_on_oob, 'Instance complexity on out of distribution dataset')\n",
    "\n",
    "results32_on_oob_more_than_1_05 = get_results_instance_complexity_more_than(results32_on_oob, 1.05)\n",
    "\n",
    "plot_instance_complexity_histogram(results32_on_oob_more_than_1_05, 'Instance complexity on out of distribution dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results32_on_oob.filter(like='Optimal F').describe())\n",
    "print(results32_on_oob_more_than_1_05.filter(like='Optimal F').describe())\n",
    "\n",
    "print(results32_on_oob.filter(like='Path L').describe())\n",
    "print(results32_on_oob_more_than_1_05.filter(like='Path L').describe())\n",
    "\n",
    "print(results32_on_oob.filter(like='Exp').describe())\n",
    "print(results32_on_oob_more_than_1_05.filter(like='Exp').describe())\n",
    "\n",
    "print(results32_on_oob.filter(like='Run Time ').describe())\n",
    "print(results32_on_oob_more_than_1_05.filter(like='Run Time ').describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric_divisor(results32_on_oob, ['Predicted Path Length CF', 'Predicted Path Length CF+0.25*PPM', 'Predicted Path Length CF+0.50*PPM',\n",
    "         'Predicted Path Length CF+0.75*PPM', 'Predicted Path Length CF+1*PPM', 'Predicted Path Length PPM+MAN', 'Predicted Path Length PPM+CF', 'Predicted Path Length CF/PPM'], 'Path Length Ratio', 'Path Length Ratio (%)', ['#FFD700', '#BFAC40', '#80AB80', '#408080', '#406ABF', '#007FFF', '#7F547F', \"#FFFF00\"], 'Manhattan Path Length')\n",
    "\n",
    "plot_metric_divisor(results32_on_oob, ['Predicted Path Length CF', 'Predicted Path Length CF+0.25*PPM', 'Predicted Path Length CF+0.50*PPM',\n",
    "            'Predicted Path Length CF+0.75*PPM', 'Predicted Path Length CF+1*PPM', 'Predicted Path Length PPM+MAN', 'Predicted Path Length PPM+CF', 'Predicted Path Length CF/PPM'], 'Path Length Ratio', 'Path Length Ratio (%)', ['#FFD700', '#BFAC40', '#80AB80', '#408080', '#406ABF', '#007FFF', '#7F547F', \"#FFFF00\"], 'Ground Truth Path Length')\n",
    "\n",
    "plot_metric_divisor(results32_on_oob, ['Expansion CF', 'Expansion CF+0.25*PPM', 'Expansion CF+0.50*PPM',\n",
    "            'Expansion CF+0.75*PPM', 'Expansion CF+1*PPM', 'Expansion PPM+MAN', 'Expansion PPM+CF', 'Expansion CF/PPM'], 'Expansion Ratio', 'Expansion Ratio (%)', ['#FFD700', '#BFAC40', '#80AB80', '#408080', '#406ABF', '#007FFF', '#7F547F', \"#FFFF00\"], 'Expansion Manhattan')\n",
    "\n",
    "plot_metric_divisor(results32_on_oob, ['Run Time CF', 'Run Time CF+0.25*PPM', 'Run Time CF+0.50*PPM',\n",
    "            'Run Time CF+0.75*PPM', 'Run Time CF+1*PPM', 'Run Time PPM+MAN', 'Run Time PPM+CF', 'Run Time CF/PPM'], 'Search Time Ratio', 'Search Time Ratio (%)', ['#FFD700', '#BFAC40', '#80AB80', '#408080', '#406ABF', '#007FFF', '#7F547F', \"#FFFF00\"], 'Run Time Manhattan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric_divisor_size(results32_on_oob, ['Predicted Path Length CF', 'Predicted Path Length CF+0.25*PPM', 'Predicted Path Length CF+0.50*PPM',\n",
    "         'Predicted Path Length CF+0.75*PPM', 'Predicted Path Length CF+1*PPM', 'Predicted Path Length PPM+MAN', 'Predicted Path Length PPM+CF', 'Predicted Path Length CF/PPM'], 'Path Length Ratio', 'Path Length Ratio (%)', ['#FFD700', '#BFAC40', '#80AB80', '#408080', '#406ABF', '#007FFF', '#7F547F', \"#FFFF00\"], 'Manhattan Path Length')\n",
    "\n",
    "plot_metric_divisor_size(results32_on_oob, ['Predicted Path Length CF', 'Predicted Path Length CF+0.25*PPM', 'Predicted Path Length CF+0.50*PPM',\n",
    "            'Predicted Path Length CF+0.75*PPM', 'Predicted Path Length CF+1*PPM', 'Predicted Path Length PPM+MAN', 'Predicted Path Length PPM+CF', 'Predicted Path Length CF/PPM'], 'Path Length Ratio', 'Path Length Ratio (%)', ['#FFD700', '#BFAC40', '#80AB80', '#408080', '#406ABF', '#007FFF', '#7F547F', \"#FFFF00\"], 'Ground Truth Path Length')\n",
    "\n",
    "plot_metric_divisor_size(results32_on_oob, ['Expansion CF', 'Expansion CF+0.25*PPM', 'Expansion CF+0.50*PPM',\n",
    "            'Expansion CF+0.75*PPM', 'Expansion CF+1*PPM', 'Expansion PPM+MAN', 'Expansion PPM+CF', 'Expansion CF/PPM'], 'Expansion Ratio', 'Expansion Ratio (%)', ['#FFD700', '#BFAC40', '#80AB80', '#408080', '#406ABF', '#007FFF', '#7F547F', \"#FFFF00\"], 'Expansion Manhattan')\n",
    "\n",
    "plot_metric_divisor_size(results32_on_oob, ['Run Time CF', 'Run Time CF+0.25*PPM', 'Run Time CF+0.50*PPM',\n",
    "            'Run Time CF+0.75*PPM', 'Run Time CF+1*PPM', 'Run Time PPM+MAN', 'Run Time PPM+CF', 'Run Time CF/PPM'], 'Search Time Ratio', 'Search Time Ratio (%)', ['#FFD700', '#BFAC40', '#80AB80', '#408080', '#406ABF', '#007FFF', '#7F547F', \"#FFFF00\"], 'Run Time Manhattan')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trained on Tiled-MP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tested on MP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsresized_on_32 = pd.read_csv('no_w_espoir_final_resized.csv')\n",
    "\n",
    "plot_instance_complexity_histogram(resultsresized_on_32, 'Instance complexity on 32x32 dataset')\n",
    "\n",
    "resultsresized_on_32_more_than_1_05 = get_results_instance_complexity_more_than(resultsresized_on_32, 1.05)\n",
    "\n",
    "plot_instance_complexity_histogram(resultsresized_on_32_more_than_1_05, 'Instance complexity on 32x32 dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resultsresized_on_32.filter(like='Optimal F').describe())\n",
    "print(resultsresized_on_32_more_than_1_05.filter(like='Optimal F').describe())\n",
    "\n",
    "print(resultsresized_on_32.filter(like='Path L').describe())\n",
    "print(resultsresized_on_32_more_than_1_05.filter(like='Path L').describe())\n",
    "\n",
    "print(resultsresized_on_32.filter(like='Exp').describe())\n",
    "print(resultsresized_on_32_more_than_1_05.filter(like='Exp').describe())\n",
    "\n",
    "print(resultsresized_on_32.filter(like='Run Time ').describe())\n",
    "print(resultsresized_on_32_more_than_1_05.filter(like='Run Time ').describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = plot_metric_divisor(resultsresized_on_32, ['Predicted Path Length CF', 'Predicted Path Length CF+0.25*PPM', 'Predicted Path Length CF+0.50*PPM',\n",
    "            'Predicted Path Length CF+0.75*PPM', 'Predicted Path Length CF+1*PPM', 'Predicted Path Length PPM+MAN', 'Predicted Path Length PPM+CF', 'Predicted Path Length CF/PPM'], 'MP Path Length Ratio', 'Path Length Ratio (%)', ['#FFD700', '#BFAC40', '#80AB80', '#408080', '#406ABF', '#007FFF', '#7F547F', \"#FFFF00\"], 'Manhattan Path Length', 99, 120)\n",
    "plot.savefig('path_length_ratio_mp.pdf', bbox_inches='tight', dpi=300)\n",
    "\n",
    "plot_metric_divisor(resultsresized_on_32, ['Expansion CF', 'Expansion CF+0.25*PPM', 'Expansion CF+0.50*PPM',\n",
    "            'Expansion CF+0.75*PPM', 'Expansion CF+1*PPM', 'Expansion PPM+MAN', 'Expansion PPM+CF', 'Expansion CF/PPM'], 'MP Expansion Ratio', 'Expansion Ratio (%)', ['#FFD700', '#BFAC40', '#80AB80', '#408080', '#406ABF', '#007FFF', '#7F547F', \"#FFFF00\"], 'Expansion Manhattan', 5, 90)\n",
    "plot.savefig('expansion_ratio_mp.pdf', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = plot_metric_divisor_map(resultsresized_on_32, ['Predicted Path Length CF', 'Predicted Path Length CF+0.25*PPM', 'Predicted Path Length CF+0.50*PPM',\n",
    "            'Predicted Path Length CF+0.75*PPM', 'Predicted Path Length CF+1*PPM', 'Predicted Path Length PPM+MAN', 'Predicted Path Length PPM+CF', 'Predicted Path Length CF/PPM'], 'MP Path Length Ratio', 'Path Length Ratio (%)', ['#FFD700', '#BFAC40', '#80AB80', '#408080', '#406ABF', '#007FFF', '#7F547F', \"#FFFF00\"], 'Ground Truth Path Length', None, None)\n",
    "plot.savefig('path_length_ratio_type.pdf', bbox_inches='tight', dpi=300)\n",
    "\n",
    "plot = plot_metric_divisor_map(resultsresized_on_32, ['Expansion CF', 'Expansion CF+0.25*PPM', 'Expansion CF+0.50*PPM',\n",
    "            'Expansion CF+0.75*PPM', 'Expansion CF+1*PPM', 'Expansion PPM+MAN', 'Expansion PPM+CF', 'Expansion CF/PPM'], 'MP Expansion Ratio', 'Expansion Ratio (%)', ['#FFD700', '#BFAC40', '#80AB80', '#408080', '#406ABF', '#007FFF', '#7F547F', \"#FFFF00\"], 'Expansion Manhattan', None, None)\n",
    "plot.savefig('expansion_ratio_type.pdf', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tested on Tiled-MP + Time Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsresized_on_resized = pd.read_csv('no_w_resized_espoir_results_on_new_dataset.csv')\n",
    "\n",
    "plot_instance_complexity_histogram(resultsresized_on_resized, 'Instance complexity on resized dataset')\n",
    "\n",
    "resultsresized_on_resized_more_than_1_05 = get_results_instance_complexity_more_than(resultsresized_on_resized, 1.05)\n",
    "\n",
    "plot_instance_complexity_histogram(resultsresized_on_resized_more_than_1_05, 'Instance complexity on resized dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resultsresized_on_resized.filter(like='Optimal F').describe())\n",
    "print(resultsresized_on_resized_more_than_1_05.filter(like='Optimal F').describe())\n",
    "\n",
    "print(resultsresized_on_resized.filter(like='Path L').describe())\n",
    "print(resultsresized_on_resized_more_than_1_05.filter(like='Path L').describe())\n",
    "\n",
    "print(resultsresized_on_resized.filter(like='Exp').describe())\n",
    "print(resultsresized_on_resized_more_than_1_05.filter(like='Exp').describe())\n",
    "\n",
    "print(resultsresized_on_resized.filter(like='Run Time ').describe())\n",
    "print(resultsresized_on_resized_more_than_1_05.filter(like='Run Time ').describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = plot_metric_divisor(resultsresized_on_resized, ['Predicted Path Length CF', 'Predicted Path Length CF+0.25*PPM', 'Predicted Path Length CF+0.50*PPM',\n",
    "            'Predicted Path Length CF+0.75*PPM', 'Predicted Path Length CF+1*PPM', 'Predicted Path Length PPM+MAN', 'Predicted Path Length PPM+CF', 'Predicted Path Length CF/PPM'], 'Tiled-MP Path Length Ratio', 'Path Length Ratio (%)', ['#FFD700', '#BFAC40', '#80AB80', '#408080', '#406ABF', '#007FFF', '#7F547F', \"#FFFF00\"], 'Manhattan Path Length', None, None)\n",
    "plot.savefig('path_length_ratio_tiled_mp.pdf', bbox_inches='tight', dpi=300)\n",
    "\n",
    "plot = plot_metric_divisor(resultsresized_on_resized, ['Expansion CF', 'Expansion CF+0.25*PPM', 'Expansion CF+0.50*PPM',\n",
    "            'Expansion CF+0.75*PPM', 'Expansion CF+1*PPM', 'Expansion PPM+MAN', 'Expansion PPM+CF', 'Expansion CF/PPM'], 'Tiled-MP Expansion Ratio', 'Expansion Ratio (%)', ['#FFD700', '#BFAC40', '#80AB80', '#408080', '#406ABF', '#007FFF', '#7F547F', \"#FFFF00\"], 'Expansion Manhattan', None, None)\n",
    "plot.savefig('expansion_ratio_tiled_mp.pdf', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print descriptive statistics for the results run time inference cf and ppm\n",
    "# multiply run time inference cf by 1000\n",
    "resultsresized_on_resized = pd.read_csv('no_w_resized_espoir_results_on_new_dataset.csv')\n",
    "print(resultsresized_on_resized.filter(like='Run Time').mean())\n",
    "\n",
    "resultsresized_on_32 = pd.read_csv('no_w_espoir_final_resized.csv')\n",
    "print(resultsresized_on_32.filter(like='Run Time').mean(), resultsresized_on_32.filter(like='Run Time').std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ici\n",
    "\n",
    "resultsresized_on_resized = pd.read_csv('no_w_resized_espoir_results_on_new_dataset.csv')\n",
    "#resultsresized_on_resized['Run Time CF'] = resultsresized_on_resized['Run Time CF']/1000\n",
    "#resultsresized_on_resized['Run Time CF+0.25*PPM'] = resultsresized_on_resized['Run Time CF+0.25*PPM']/1000\n",
    "#resultsresized_on_resized['Run Time CF+0.50*PPM'] = resultsresized_on_resized['Run Time CF+0.50*PPM']/1000\n",
    "#resultsresized_on_resized['Run Time CF+0.75*PPM'] = resultsresized_on_resized['Run Time CF+0.75*PPM']/1000\n",
    "#resultsresized_on_resized['Run Time CF+1*PPM'] = resultsresized_on_resized['Run Time CF+1*PPM']/1000\n",
    "#resultsresized_on_resized['Run Time CF/PPM'] = resultsresized_on_resized['Run Time CF/PPM']/1000\n",
    "\n",
    "\n",
    "plot = plot_metric_divisor_size(resultsresized_on_resized, ['Run Time CF', 'Run Time CF+0.25*PPM', 'Run Time CF+0.50*PPM',\n",
    "            'Run Time CF+0.75*PPM', 'Run Time CF+1*PPM', 'Run Time CF/PPM'], 'Total Search Time', 'Run time (s)', ['#FFD700', '#BFAC40', '#80AB80', '#408080', '#406ABF', \"#FFFF00\"], 'Run Time Manhattan')\n",
    "#plot.savefig('total_search_time_resized.pdf', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsresized_on_resized = pd.read_csv('no_w_resized_espoir_results_on_new_dataset.csv')\n",
    "#same for inference time cf and ppm\n",
    "\n",
    "plot = plot_metric_divisor_size(resultsresized_on_resized, ['Run Time Inference CF', 'Run Time Inference PPM'], 'Inference Time', 'Run time (ms)', ['#FFD700', '#007FFF'], None)\n",
    "plot.savefig('inference_time_resized.pdf', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resultsresized_on_resized[\"Run Time CF\"].mean())\n",
    "print(resultsresized_on_resized[\"Run Time Manhattan\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter 'Run Time Manhattan' in blue vs 'Ground Truth Path Length' in x\n",
    "resultsresized_on_resized = pd.read_csv('no_w_resized_espoir_results_on_new_dataset.csv')\n",
    "\n",
    "# remove outliers in 'Run Time Manhattan' and 'Run Time Inference CF' and 'Run Time CF/PPM', outliers are values percentage of 0.1% and 99.9%\n",
    "#resultsresized_on_resized = resultsresized_on_resized[(resultsresized_on_resized['Run Time Manhattan'] >= resultsresized_on_resized['Run Time Manhattan'].quantile(0.1)) & (resultsresized_on_resized['Run Time Manhattan'] <= resultsresized_on_resized['Run Time Manhattan'].quantile(0.9))]\n",
    "#resultsresized_on_resized = resultsresized_on_resized[(resultsresized_on_resized['Run Time Inference CF'] >= resultsresized_on_resized['Run Time Inference CF'].quantile(0.1)) & (resultsresized_on_resized['Run Time Inference CF'] <= resultsresized_on_resized['Run Time Inference CF'].quantile(0.9))]\n",
    "#resultsresized_on_resized = resultsresized_on_resized[(resultsresized_on_resized['Run Time CF/PPM'] >= resultsresized_on_resized['Run Time CF/PPM'].quantile(0.1)) & (resultsresized_on_resized['Run Time CF/PPM'] <= resultsresized_on_resized['Run Time CF/PPM'].quantile(0.9))]\n",
    "\n",
    "resultsresized_on_resized = resultsresized_on_resized.sort_values(by='Ground Truth Path Length')\n",
    "\n",
    "# do /1000 to convert ms to s\n",
    "resultsresized_on_resized['Run Time Manhattan'] = resultsresized_on_resized['Run Time Manhattan']/1000\n",
    "resultsresized_on_resized['Run Time Inference CF'] = resultsresized_on_resized['Run Time Inference CF']/1000\n",
    "resultsresized_on_resized['Run Time CF'] = resultsresized_on_resized['Run Time CF']/1000\n",
    "\n",
    "\n",
    "plt.scatter(resultsresized_on_resized['Ground Truth Path Length'], resultsresized_on_resized['Run Time Manhattan'], color='#777777', alpha=0.5, s=20, edgecolors='black', linewidths=0.2)\n",
    "plt.scatter(resultsresized_on_resized['Ground Truth Path Length'], resultsresized_on_resized['Run Time Inference CF'] + resultsresized_on_resized['Run Time CF'], color='red', alpha=0.8, s=20, edgecolors='black', linewidths=0.2)\n",
    "plt.scatter(resultsresized_on_resized['Ground Truth Path Length'], resultsresized_on_resized['Run Time Inference CF'], color='#FFD700', alpha=0.8, s=20, edgecolors='black', linewidths=0.2)\n",
    "plt.xlabel('Path Length', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Run Time (s)', fontsize=14, fontweight='bold')\n",
    "plt.title('Run Time against Path Length', fontsize=18, fontweight='bold', pad=10)\n",
    "plt.ylim(0, 2.5)\n",
    "plt.xlim(20, 360)\n",
    "xticks = [20, 50, 100, 150, 200, 250, 300, 350]\n",
    "yticks = [0, 0.5, 1, 1.5, 2, 2.5]\n",
    "plt.xticks(xticks)\n",
    "plt.yticks(yticks)\n",
    "\n",
    "plt.legend(['A*+MAN Total Time', 'WA*+CF Total Time', 'CF Inference Time'], loc='best')\n",
    "# sort the values by 'Ground Truth Path Length'\n",
    "#resultsresized_on_resized = resultsresized_on_resized.sort_values(by='Ground Truth Path Length')\n",
    "#do z = np.polyfit(resultsresized_on_resized['Ground Truth Path Length'], resultsresized_on_resized['Run Time Manhattan'], 2) between 15 and 250 and 0 and 600\n",
    "# limit the values of resultsresized_on_resized['Ground Truth Path Length'] to 15 and 250\n",
    "#resultsresized_on_resized = resultsresized_on_resized[(resultsresized_on_resized['Ground Truth Path Length'] >= 15) & (resultsresized_on_resized['Ground Truth Path Length'] <= 250)]\n",
    "#resultsresized_on_resized = resultsresized_on_resized[(resultsresized_on_resized['Run Time Manhattan'] >= 0) & (resultsresized_on_resized['Run Time Manhattan'] <= 600)]\n",
    "#resultsresized_on_resized = resultsresized_on_resized[(resultsresized_on_resized['Run Time Inference CF'] >= 0) & (resultsresized_on_resized['Run Time Inference CF'] <= 600)]\n",
    "#resultsresized_on_resized = resultsresized_on_resized[(resultsresized_on_resized['Run Time CF'] >= 0) & (resultsresized_on_resized['Run Time CF'] <= 1200)]\n",
    "z = np.polyfit(resultsresized_on_resized['Ground Truth Path Length'], resultsresized_on_resized['Run Time Manhattan'], 2)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(resultsresized_on_resized['Ground Truth Path Length'], p(resultsresized_on_resized['Ground Truth Path Length']), '#333333', linestyle='-', linewidth=2, alpha=0.8)\n",
    "plt.fill_between(resultsresized_on_resized['Ground Truth Path Length'], p(resultsresized_on_resized['Ground Truth Path Length']) - resultsresized_on_resized['Run Time Manhattan'].std(), p(resultsresized_on_resized['Ground Truth Path Length']) + resultsresized_on_resized['Run Time Manhattan'].std(), color='#777777', alpha=0.1)\n",
    "z = np.polyfit(resultsresized_on_resized['Ground Truth Path Length'], resultsresized_on_resized['Run Time Inference CF'], 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(resultsresized_on_resized['Ground Truth Path Length'], p(resultsresized_on_resized['Ground Truth Path Length']), '#996700', linestyle='-', linewidth=2, alpha=0.8)\n",
    "plt.fill_between(resultsresized_on_resized['Ground Truth Path Length'], p(resultsresized_on_resized['Ground Truth Path Length']) - resultsresized_on_resized['Run Time Inference CF'].std(), p(resultsresized_on_resized['Ground Truth Path Length']) + resultsresized_on_resized['Run Time Inference CF'].std(), color='#FFD700', alpha=0.05)\n",
    "z = np.polyfit(resultsresized_on_resized['Ground Truth Path Length'], resultsresized_on_resized['Run Time Inference CF']+resultsresized_on_resized['Run Time CF'], 2)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(resultsresized_on_resized['Ground Truth Path Length'], p(resultsresized_on_resized['Ground Truth Path Length']), 'darkred', linestyle='-', linewidth=2)\n",
    "plt.fill_between(resultsresized_on_resized['Ground Truth Path Length'], p(resultsresized_on_resized['Ground Truth Path Length']) - resultsresized_on_resized['Run Time Inference CF'].std() - resultsresized_on_resized['Run Time CF'].std(), p(resultsresized_on_resized['Ground Truth Path Length']) + resultsresized_on_resized['Run Time Inference CF'].std() + resultsresized_on_resized['Run Time CF'].std(), color='red', alpha=0.1)\n",
    "# add a black dotted line at x = 50\n",
    "plt.axvline(x=54, color='black', linestyle='--', linewidth=2, alpha=0.9)\n",
    "plt.text(55, -0.11, '54', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.savefig('run_time_vs_path_length.pdf', bbox_inches='tight', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import mtick PercentFormatter\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "import matplotlib.ticker as mtick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot importance of resultsresized_on_resized['Run Time Inference CF'] and resultsresized_on_resized['Run Time CF'] over the path length\n",
    "# importance is the ratio of the run time over the total run time\n",
    "plt.scatter(resultsresized_on_resized['Ground Truth Path Length'], resultsresized_on_resized['Run Time Inference CF'] / (resultsresized_on_resized['Run Time Inference CF'] + resultsresized_on_resized['Run Time CF']), color='#FFD700', alpha=1, s=20, edgecolors='black', linewidths=0.2, zorder=5)\n",
    "plt.scatter(resultsresized_on_resized['Ground Truth Path Length'], resultsresized_on_resized['Run Time CF'] / (resultsresized_on_resized['Run Time Inference CF'] + resultsresized_on_resized['Run Time CF']), color='red', alpha=0.5, s=20, edgecolors='black', linewidths=0.2)\n",
    "plt.xlabel('Path Length', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Importance', fontsize=14, fontweight='bold')\n",
    "plt.title('Search VS Inference Time Importance', fontsize=18, fontweight='bold', pad=10)\n",
    "plt.legend(['CF Inference Time', 'WA*+CF Search Time'], loc='best')\n",
    "# use 1-exp(-x) to have a better view of the importance\n",
    "xticks = [20, 50, 100, 150, 200, 250, 300, 350]\n",
    "yticks = [0, 0.25, 0.5, 0.75, 1]\n",
    "# multiply by 100 to have a percentage\n",
    "plt.xlim(20, 360)\n",
    "plt.ylim(0, 1)\n",
    "plt.xticks(xticks)\n",
    "plt.yticks(yticks)\n",
    "# change the yticks labels to percentage\n",
    "plt.gca().yaxis.set_major_formatter(mtick.PercentFormatter(1))\n",
    "plt.plot(resultsresized_on_resized['Ground Truth Path Length'], -0.025+(1-np.exp(0.05-resultsresized_on_resized['Ground Truth Path Length']/40)), 'darkred', linestyle='-', linewidth=2, alpha=0.5, zorder=8)\n",
    "plt.plot(resultsresized_on_resized['Ground Truth Path Length'], 0.025 + (np.exp(0.05-resultsresized_on_resized['Ground Truth Path Length']/40)), '#996700', linestyle='-', linewidth=2, zorder=10)\n",
    "plt.axvline(x=31.5, color='black', linestyle='--', linewidth=2, zorder=11, alpha=0.9)\n",
    "plt.text(34, -0.04, '32', fontsize=12, fontweight='bold', color='black', ha='center')\n",
    "plt.text(343, 0.04, '2.5%', fontsize=12, fontweight='bold', color='black', ha='center', zorder=12)\n",
    "plt.savefig('importance_vs_path_length.pdf', bbox_inches='tight', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = plot_metric_divisor_size(resultsresized_on_resized, ['Predicted Path Length CF', 'Predicted Path Length CF+0.25*PPM', 'Predicted Path Length CF+0.50*PPM',\n",
    "            'Predicted Path Length CF+0.75*PPM', 'Predicted Path Length CF+1*PPM', 'Predicted Path Length PPM+MAN', 'Predicted Path Length PPM+CF', 'Predicted Path Length CF/PPM'], 'Tiled-MP Path Length Ratio', 'Path Length Ratio (%)', ['#FFD700', '#BFAC40', '#80AB80', '#408080', '#406ABF', '#007FFF', '#7F547F', \"#FFFF00\"], 'Manhattan Path Length', 99, 160)\n",
    "plot.savefig('path_length_ratio_tiled_mp_size.pdf', bbox_inches='tight', dpi=300)\n",
    "\n",
    "plot = plot_metric_divisor_size(resultsresized_on_resized, ['Expansion CF', 'Expansion CF+0.25*PPM', 'Expansion CF+0.50*PPM',\n",
    "            'Expansion CF+0.75*PPM', 'Expansion CF+1*PPM', 'Expansion PPM+MAN', 'Expansion PPM+CF', 'Expansion CF/PPM'], 'Tiled-MP Expansion Ratio', 'Expansion Ratio (%)', ['#FFD700', '#BFAC40', '#80AB80', '#408080', '#406ABF', '#007FFF', '#7F547F', \"#FFFF00\"], 'Expansion Manhattan', 0, 200)\n",
    "plot.savefig('expansion_ratio_tiled_mp_size.pdf', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tested on ood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsresized_on_oob = pd.read_csv('no_w_resized_espoir_out_of_distrib_NON_resized.csv')\n",
    "\n",
    "plot_instance_complexity_histogram(resultsresized_on_oob, 'Instance complexity on out of distribution dataset')\n",
    "\n",
    "resultsresized_on_oob_more_than_1_05 = get_results_instance_complexity_more_than(resultsresized_on_oob, 1.05)\n",
    "\n",
    "plot_instance_complexity_histogram(resultsresized_on_oob_more_than_1_05, 'Instance complexity on out of distribution dataset')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resultsresized_on_oob.filter(like='Optimal F').describe())\n",
    "print(resultsresized_on_oob_more_than_1_05.filter(like='Optimal F').describe())\n",
    "\n",
    "print(resultsresized_on_oob.filter(like='Path L').describe())\n",
    "print(resultsresized_on_oob_more_than_1_05.filter(like='Path L').describe())\n",
    "\n",
    "print(resultsresized_on_oob.filter(like='Exp').describe())\n",
    "print(resultsresized_on_oob_more_than_1_05.filter(like='Exp').describe())\n",
    "\n",
    "print(resultsresized_on_oob.filter(like='Run Time ').describe())\n",
    "print(resultsresized_on_oob_more_than_1_05.filter(like='Run Time ').describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = plot_metric_divisor(resultsresized_on_oob, ['Predicted Path Length CF', 'Predicted Path Length CF+0.25*PPM', 'Predicted Path Length CF+0.50*PPM',\n",
    "            'Predicted Path Length CF+0.75*PPM', 'Predicted Path Length CF+1*PPM', 'Predicted Path Length PPM+MAN', 'Predicted Path Length PPM+CF', 'Predicted Path Length CF/PPM'], 'o-o-d Path Length Ratio', 'Path Length Ratio (%)', ['#FFD700', '#BFAC40', '#80AB80', '#408080', '#406ABF', '#007FFF', '#7F547F', \"#FFFF00\"], 'Manhattan Path Length', 99, 160)\n",
    "plot.savefig('path_length_ratio_oob.pdf', bbox_inches='tight', dpi=300)\n",
    "\n",
    "plot = plot_metric_divisor(resultsresized_on_oob, ['Expansion CF', 'Expansion CF+0.25*PPM', 'Expansion CF+0.50*PPM',\n",
    "            'Expansion CF+0.75*PPM', 'Expansion CF+1*PPM', 'Expansion PPM+MAN', 'Expansion PPM+CF', 'Expansion CF/PPM'], 'o-o-d Expansion Ratio', 'Expansion Ratio (%)', ['#FFD700', '#BFAC40', '#80AB80', '#408080', '#406ABF', '#007FFF', '#7F547F', \"#FFFF00\"], 'Expansion Manhattan', 0, 200)\n",
    "plot.savefig('expansion_ratio_oob.pdf', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsresized_on_oob = pd.read_csv('no_w_resized_espoir_out_of_distrib_NON_resized.csv')\n",
    "\n",
    "street = ['Berlin', 'Boston', 'Denver', 'London', 'Milan', 'Moscow', 'NewYork', 'Paris', 'Shanghai', 'Sydney']\n",
    "maze = 'maze'\n",
    "bgmaps = 'AR0'\n",
    "\n",
    "# add a column to resultsresized_on_oob with 'da2' as the value\n",
    "resultsresized_on_oob['type'] = 'da2'\n",
    "\n",
    "# go through every line, if there is a street in the instance name, put the 'type' column as 'street'\n",
    "for i in range(len(resultsresized_on_oob)):\n",
    "    for s in street:\n",
    "        if s in resultsresized_on_oob.at[i, \"Name\"]:\n",
    "            resultsresized_on_oob.at[i, 'type'] = 'street'\n",
    "\n",
    "# go through every line, if there is a maze in the instance name, put the 'type' column as 'maze'\n",
    "for i in range(len(resultsresized_on_oob)):\n",
    "    if maze in resultsresized_on_oob.at[i, \"Name\"]:\n",
    "        resultsresized_on_oob.at[i, 'type'] = 'maze'\n",
    "\n",
    "# go through every line, if there is a bgmaps in the instance name, put the 'type' column as 'bgmaps'\n",
    "for i in range(len(resultsresized_on_oob)):\n",
    "    if bgmaps in resultsresized_on_oob.at[i, \"Name\"]:\n",
    "        resultsresized_on_oob.at[i, 'type'] = 'bgmaps'\n",
    "\n",
    "def plot_metric_divisor_map2(results, metrics, title, ylabel, colors, divisor, yminlim, ymaxlim):\n",
    "    \"\"\"\n",
    "    Plot the metrics based on the Type of map.\n",
    "\n",
    "    Parameters:\n",
    "        results: DataFrame containing the data.\n",
    "        metrics: List of metrics (strings) to be plotted.\n",
    "        title: Title of the plot.\n",
    "        ylabel: Label for the y-axis.\n",
    "        colors: List of colors for each metric's box plot.\n",
    "    \"\"\"\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 4))\n",
    "    \n",
    "    # get type of map from the results unique\n",
    "    type_of_map = results['type'].unique()\n",
    "    \n",
    "    # Define Instance Complexity ranges\n",
    "    results_1 = results[results['type'] == type_of_map[0]]\n",
    "    results_2 = results[results['type'] == type_of_map[1]]\n",
    "    results_3 = results[results['type'] == type_of_map[2]]\n",
    "    results_4 = results[results['type'] == type_of_map[3]]\n",
    "    \n",
    "    labels = [type_of_map[0], type_of_map[1], type_of_map[2], type_of_map[3]] #, type_of_map[4], type_of_map[5], type_of_map[6], type_of_map[7]]\n",
    "    \n",
    "    new_labels = labels\n",
    "    for i, label in enumerate(new_labels):\n",
    "        if label == \"bgmaps\":\n",
    "            new_labels[i] = \"BigGameHunters\"\n",
    "        elif label == \"maze\":\n",
    "            new_labels[i] = \"Maze\"\n",
    "        elif label == \"da2\":\n",
    "            new_labels[i] = \"DragonAge2\"\n",
    "        elif label == \"street\":\n",
    "            new_labels[i] = \"Street\"\n",
    "    labels = new_labels\n",
    "    \n",
    "    # Prepare data for each metric\n",
    "    data = []\n",
    "    for metric in metrics:\n",
    "        if divisor is not None:\n",
    "            data.append([\n",
    "                100 * results_1[metric] / results_1[divisor],\n",
    "                100 * results_2[metric] / results_2[divisor],\n",
    "                100 * results_3[metric] / results_3[divisor],\n",
    "                100 * results_4[metric] / results_4[divisor]\n",
    "            ])\n",
    "        else:\n",
    "            data.append([\n",
    "                results_1[metric], \n",
    "                results_2[metric], \n",
    "                results_3[metric], \n",
    "                results_4[metric]\n",
    "            ])\n",
    "        \n",
    "    # Plot each metric's boxplot with different colors\n",
    "    num_metrics = len(metrics)\n",
    "    positions = np.arange(len(labels)) * (num_metrics + 2)\n",
    "\n",
    "    # Plot each metric's boxplot with different colors\n",
    "    for i, metric_data in enumerate(data):\n",
    "        bplot = ax.boxplot(\n",
    "            metric_data, \n",
    "            positions=positions + i * 0.9 - 0.1, \n",
    "            widths=0.6, \n",
    "            patch_artist=True, \n",
    "            meanline=True, \n",
    "            showfliers=False, \n",
    "            notch=True, \n",
    "            autorange=True, \n",
    "            showmeans=True, \n",
    "            meanprops=dict(marker='', color='r'), \n",
    "            medianprops=dict(color='k')\n",
    "        )\n",
    "        \n",
    "        for patch in bplot['boxes']:\n",
    "            patch.set_facecolor(colors[i])\n",
    "            \n",
    "    # Set x-axis labels and positions\n",
    "    ax.set_xticks(positions + (num_metrics / 2) - 1)\n",
    "    \n",
    "    \n",
    "    #use ymaxlim to set the y-axis limit\n",
    "    if ymaxlim is not None:\n",
    "        ax.set_ylim(yminlim, ymaxlim)\n",
    "    \n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.set_xlabel('Type of map', fontsize=14, fontweight='bold')\n",
    "    ax.set_ylabel(ylabel, fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Add title and legend\n",
    "    plt.title(title + ' depending on the Type of map', fontsize=18, fontweight='bold')\n",
    "    plt.legend([plt.Rectangle((0,0),1,1,fc=colors[i], ec='k') for i in range(len(metrics))], [metric.split(\" \")[-1] for metric in metrics], loc='best')\n",
    "    \n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    return plt\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = plot_metric_divisor_map2(resultsresized_on_oob, ['Predicted Path Length CF', 'Predicted Path Length CF+0.25*PPM', 'Predicted Path Length CF+0.50*PPM',\n",
    "            'Predicted Path Length CF+0.75*PPM', 'Predicted Path Length CF+1*PPM', 'Predicted Path Length PPM+MAN', 'Predicted Path Length PPM+CF', 'Predicted Path Length CF/PPM'], 'o-o-d Path Length Ratio', 'Path Length Ratio (%)', ['#FFD700', '#BFAC40', '#80AB80', '#408080', '#406ABF', '#007FFF', '#7F547F', \"#FFFF00\"], 'Manhattan Path Length', 99, 180)\n",
    "plot.savefig('path_length_ratio_oob_type.pdf', bbox_inches='tight', dpi=300)\n",
    "\n",
    "plot = plot_metric_divisor_map2(resultsresized_on_oob, ['Expansion CF', 'Expansion CF+0.25*PPM', 'Expansion CF+0.50*PPM',\n",
    "            'Expansion CF+0.75*PPM', 'Expansion CF+1*PPM', 'Expansion PPM+MAN', 'Expansion PPM+CF', 'Expansion CF/PPM'], 'o-o-d Expansion Ratio', 'Expansion Ratio (%)', ['#FFD700', '#BFAC40', '#80AB80', '#408080', '#406ABF', '#007FFF', '#7F547F', \"#FFFF00\"], 'Expansion Manhattan', 0, 250)\n",
    "plot.savefig('expansion_ratio_oob_type.pdf', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stats Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results32_on_32 = pd.read_csv('32_espoir_on_32.csv')\n",
    "resultsresized_on_32 = pd.read_csv('resized_espoir_on_32.csv')\n",
    "\n",
    "# print mean and std of the optimal F value\n",
    "results32_opti = results32_on_32.filter(like='Optimal F')\n",
    "resultsresized_opti = resultsresized_on_32.filter(like='Optimal F')\n",
    "\n",
    "results32_path = results32_on_32.filter(like='Path L')\n",
    "resultsresized_path = resultsresized_on_32.filter(like='Path L')\n",
    "\n",
    "results32_exp = results32_on_32.filter(like='Exp')\n",
    "resultsresized_exp = resultsresized_on_32.filter(like='Exp')\n",
    "\n",
    "for col in results32_opti.columns:\n",
    "    print(col, results32_opti[col].mean().round(2), results32_opti[col].std().round(2), resultsresized_opti[col].mean().round(2), resultsresized_opti[col].std().round(2))\n",
    "\n",
    "print()\n",
    "for col in results32_path.columns:\n",
    "    print(col, 100*(results32_path[col]/results32_path['Ground Truth Path Length']).mean().round(4), 100*(results32_path[col]/results32_path['Ground Truth Path Length']).std().round(4), 100*(resultsresized_path[col]/resultsresized_path['Ground Truth Path Length']).mean().round(4), 100*(resultsresized_path[col]/resultsresized_path['Ground Truth Path Length']).std().round(4))\n",
    "\n",
    "print()\n",
    "for col in results32_exp.columns:\n",
    "    if col == 'Expansion Manhattan' or col == 'Expansion GT':\n",
    "        continue\n",
    "    print(col, 100*(results32_exp[col]/results32_exp['Expansion Manhattan']).mean().round(4), 100*(results32_exp[col]/results32_exp['Expansion Manhattan']).std().round(4), 100*(resultsresized_exp[col]/resultsresized_exp['Expansion Manhattan']).mean().round(4), 100*(resultsresized_exp[col]/resultsresized_exp['Expansion Manhattan']).std().round(4))\n",
    "\n",
    "results32_time = results32_on_32.filter(like='Time')\n",
    "resultsresized_time = resultsresized_on_32.filter(like='Time')\n",
    "\n",
    "print()\n",
    "for col in results32_time.columns:\n",
    "    if \"Inference\" in col:\n",
    "        print(col, (results32_time[col]).mean().round(2), (results32_time[col]).std().round(2), (resultsresized_time[col]).mean().round(2), (resultsresized_time[col]).std().round(2))\n",
    "    else:\n",
    "        if \"PPM\" in col and \"CF\" in col:\n",
    "            print(col, (results32_time[col]+results32_on_32['Run Time Inference CF']+results32_on_32['Run Time Inference PPM']).mean().round(2), (results32_time[col]+results32_on_32['Run Time Inference CF']+results32_on_32['Run Time Inference PPM']).std().round(2), (resultsresized_time[col]+resultsresized_on_32['Run Time Inference CF']+resultsresized_on_32['Run Time Inference PPM']).mean().round(2), (resultsresized_time[col]+resultsresized_on_32['Run Time Inference CF']+resultsresized_on_32['Run Time Inference PPM']).std().round(2))\n",
    "        elif \"PPM\" in col:\n",
    "            print(col, (results32_time[col]+results32_on_32['Run Time Inference PPM']).mean().round(2), (results32_time[col]+results32_on_32['Run Time Inference PPM']).std().round(2), (resultsresized_time[col]+resultsresized_on_32['Run Time Inference PPM']).mean().round(2), (resultsresized_time[col]+resultsresized_on_32['Run Time Inference PPM']).std().round(2))\n",
    "        elif \"CF\" in col:\n",
    "            print(col, (results32_time[col]+results32_on_32['Run Time Inference CF']).mean().round(2), (results32_time[col]+results32_on_32['Run Time Inference CF']).std().round(2), (resultsresized_time[col]+resultsresized_on_32['Run Time Inference CF']).mean().round(2), (resultsresized_time[col]+resultsresized_on_32['Run Time Inference CF']).std().round(2))\n",
    "        else:\n",
    "            print(col, (results32_time[col]).mean().round(2), (results32_time[col]).std().round(2), (resultsresized_time[col]).mean().round(2), (resultsresized_time[col]).std().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results32_on_resized = pd.read_csv('32_espoir_results_on_new_dataset.csv')\n",
    "resultsresized_on_resized = pd.read_csv('resized_espoir_results_on_new_dataset.csv')\n",
    "\n",
    "results32_opti = results32_on_resized.filter(like='Optimal F')\n",
    "resultsresized_opti = resultsresized_on_resized.filter(like='Optimal F')\n",
    "\n",
    "results32_path = results32_on_resized.filter(like='Path L')\n",
    "resultsresized_path = resultsresized_on_resized.filter(like='Path L')\n",
    "\n",
    "results32_exp = results32_on_resized.filter(like='Exp')\n",
    "resultsresized_exp = resultsresized_on_resized.filter(like='Exp')\n",
    "\n",
    "for col in results32_opti.columns:\n",
    "    print(col, results32_opti[col].mean().round(2), results32_opti[col].std().round(2), resultsresized_opti[col].mean().round(2), resultsresized_opti[col].std().round(2))\n",
    "\n",
    "print()\n",
    "for col in results32_path.columns:\n",
    "    print(col, 100*(results32_path[col]/results32_path['Ground Truth Path Length']).mean().round(4), 100*(results32_path[col]/results32_path['Ground Truth Path Length']).std().round(4), 100*(resultsresized_path[col]/resultsresized_path['Ground Truth Path Length']).mean().round(4), 100*(resultsresized_path[col]/resultsresized_path['Ground Truth Path Length']).std().round(4))\n",
    "\n",
    "print()\n",
    "for col in results32_exp.columns:\n",
    "    if col == 'Expansion Manhattan' or col == 'Expansion GT':\n",
    "        continue\n",
    "    print(col, 100*(results32_exp[col]/results32_exp['Expansion Manhattan']).mean().round(4), 100*(results32_exp[col]/results32_exp['Expansion Manhattan']).std().round(4), 100*(resultsresized_exp[col]/resultsresized_exp['Expansion Manhattan']).mean().round(4), 100*(resultsresized_exp[col]/resultsresized_exp['Expansion Manhattan']).std().round(4))\n",
    "\n",
    "results32_time = results32_on_resized.filter(like='Time')\n",
    "resultsresized_time = resultsresized_on_resized.filter(like='Time')\n",
    "\n",
    "print()\n",
    "for col in results32_time.columns:\n",
    "    if \"Inference\" in col:\n",
    "        print(col, (results32_time[col]).mean().round(2), (results32_time[col]).std().round(2), (resultsresized_time[col]).mean().round(2), (resultsresized_time[col]).std().round(2))\n",
    "    else:\n",
    "        if \"PPM\" in col and \"CF\" in col:\n",
    "            print(col, (results32_time[col]+results32_on_32['Run Time Inference CF']+results32_on_32['Run Time Inference PPM']).mean().round(2), (results32_time[col]+results32_on_32['Run Time Inference CF']+results32_on_32['Run Time Inference PPM']).std().round(2), (resultsresized_time[col]+resultsresized_on_32['Run Time Inference CF']+resultsresized_on_32['Run Time Inference PPM']).mean().round(2), (resultsresized_time[col]+resultsresized_on_32['Run Time Inference CF']+resultsresized_on_32['Run Time Inference PPM']).std().round(2))\n",
    "        elif \"PPM\" in col:\n",
    "            print(col, (results32_time[col]+results32_on_32['Run Time Inference PPM']).mean().round(2), (results32_time[col]+results32_on_32['Run Time Inference PPM']).std().round(2), (resultsresized_time[col]+resultsresized_on_32['Run Time Inference PPM']).mean().round(2), (resultsresized_time[col]+resultsresized_on_32['Run Time Inference PPM']).std().round(2))\n",
    "        elif \"CF\" in col:\n",
    "            print(col, (results32_time[col]+results32_on_32['Run Time Inference CF']).mean().round(2), (results32_time[col]+results32_on_32['Run Time Inference CF']).std().round(2), (resultsresized_time[col]+resultsresized_on_32['Run Time Inference CF']).mean().round(2), (resultsresized_time[col]+resultsresized_on_32['Run Time Inference CF']).std().round(2))\n",
    "        else:\n",
    "            print(col, (results32_time[col]).mean().round(2), (results32_time[col]).std().round(2), (resultsresized_time[col]).mean().round(2), (resultsresized_time[col]).std().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results32_on_oob = pd.read_csv('32_espoir_out_of_distrib.csv')\n",
    "resultsresized_on_oob = pd.read_csv('resized_espoir_out_of_distrib.csv')\n",
    "\n",
    "results32_opti = results32_on_oob.filter(like='Optimal F')\n",
    "resultsresized_opti = resultsresized_on_oob.filter(like='Optimal F')\n",
    "\n",
    "results32_path = results32_on_oob.filter(like='Path L')\n",
    "resultsresized_path = resultsresized_on_oob.filter(like='Path L')\n",
    "\n",
    "results32_exp = results32_on_oob.filter(like='Exp')\n",
    "resultsresized_exp = resultsresized_on_oob.filter(like='Exp')\n",
    "\n",
    "for col in results32_opti.columns:\n",
    "    print(col, results32_opti[col].mean().round(2), results32_opti[col].std().round(2), resultsresized_opti[col].mean().round(2), resultsresized_opti[col].std().round(2))\n",
    "\n",
    "print()\n",
    "for col in results32_path.columns:\n",
    "    print(col, 100*(results32_path[col]/results32_path['Ground Truth Path Length']).mean().round(4), 100*(results32_path[col]/results32_path['Ground Truth Path Length']).std().round(4), 100*(resultsresized_path[col]/resultsresized_path['Ground Truth Path Length']).mean().round(4), 100*(resultsresized_path[col]/resultsresized_path['Ground Truth Path Length']).std().round(4))\n",
    "\n",
    "print()\n",
    "for col in results32_exp.columns:\n",
    "    if col == 'Expansion Manhattan' or col == 'Expansion GT':\n",
    "        continue\n",
    "    print(col, 100*(results32_exp[col]/results32_exp['Expansion Manhattan']).mean().round(4), 100*(results32_exp[col]/results32_exp['Expansion Manhattan']).std().round(4), 100*(resultsresized_exp[col]/resultsresized_exp['Expansion Manhattan']).mean().round(4), 100*(resultsresized_exp[col]/resultsresized_exp['Expansion Manhattan']).std().round(4))\n",
    "\n",
    "results32_time = results32_on_oob.filter(like='Time')\n",
    "resultsresized_time = resultsresized_on_oob.filter(like='Time')\n",
    "\n",
    "print()\n",
    "for col in results32_time.columns:\n",
    "    if \"Inference\" in col:\n",
    "        print(col, (results32_time[col]).mean().round(2), (results32_time[col]).std().round(2), (resultsresized_time[col]).mean().round(2), (resultsresized_time[col]).std().round(2))\n",
    "    else:\n",
    "        if \"PPM\" in col and \"CF\" in col:\n",
    "            print(col, (results32_time[col]+results32_on_32['Run Time Inference CF']+results32_on_32['Run Time Inference PPM']).mean().round(2), (results32_time[col]+results32_on_32['Run Time Inference CF']+results32_on_32['Run Time Inference PPM']).std().round(2), (resultsresized_time[col]+resultsresized_on_32['Run Time Inference CF']+resultsresized_on_32['Run Time Inference PPM']).mean().round(2), (resultsresized_time[col]+resultsresized_on_32['Run Time Inference CF']+resultsresized_on_32['Run Time Inference PPM']).std().round(2))\n",
    "        elif \"PPM\" in col:\n",
    "            print(col, (results32_time[col]+results32_on_32['Run Time Inference PPM']).mean().round(2), (results32_time[col]+results32_on_32['Run Time Inference PPM']).std().round(2), (resultsresized_time[col]+resultsresized_on_32['Run Time Inference PPM']).mean().round(2), (resultsresized_time[col]+resultsresized_on_32['Run Time Inference PPM']).std().round(2))\n",
    "        elif \"CF\" in col:\n",
    "            print(col, (results32_time[col]+results32_on_32['Run Time Inference CF']).mean().round(2), (results32_time[col]+results32_on_32['Run Time Inference CF']).std().round(2), (resultsresized_time[col]+resultsresized_on_32['Run Time Inference CF']).mean().round(2), (resultsresized_time[col]+resultsresized_on_32['Run Time Inference CF']).std().round(2))\n",
    "        else:\n",
    "            print(col, (results32_time[col]).mean().round(2), (results32_time[col]).std().round(2), (resultsresized_time[col]).mean().round(2), (resultsresized_time[col]).std().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove instance complexity less than 1.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results32_on_32 = pd.read_csv('32_espoir_on_32.csv')\n",
    "resultsresized_on_32 = pd.read_csv('resized_espoir_on_32.csv')\n",
    "\n",
    "results32_on_32 = get_results_instance_complexity_more_than(results32_on_32, 1.05)\n",
    "resultsresized_on_32 = get_results_instance_complexity_more_than(resultsresized_on_32, 1.05)\n",
    "\n",
    "# print mean and std of the optimal F value\n",
    "results32_opti = results32_on_32.filter(like='Optimal F')\n",
    "resultsresized_opti = resultsresized_on_32.filter(like='Optimal F')\n",
    "\n",
    "results32_path = results32_on_32.filter(like='Path L')\n",
    "resultsresized_path = resultsresized_on_32.filter(like='Path L')\n",
    "\n",
    "results32_exp = results32_on_32.filter(like='Exp')\n",
    "resultsresized_exp = resultsresized_on_32.filter(like='Exp')\n",
    "\n",
    "for col in results32_opti.columns:\n",
    "    print(col, results32_opti[col].mean().round(2), resultsresized_opti[col].mean().round(2))\n",
    "\n",
    "print()\n",
    "for col in results32_path.columns:\n",
    "    print(col, 100*(results32_path[col]/results32_path['Ground Truth Path Length']).mean().round(4), 100*(results32_path[col]/results32_path['Ground Truth Path Length']).std().round(4), 100*(resultsresized_path[col]/resultsresized_path['Ground Truth Path Length']).mean().round(4), 100*(resultsresized_path[col]/resultsresized_path['Ground Truth Path Length']).std().round(4))\n",
    "\n",
    "print()\n",
    "for col in results32_exp.columns:\n",
    "    if col == 'Expansion Manhattan' or col == 'Expansion GT':\n",
    "        continue\n",
    "    print(col, 100*(results32_exp[col]/results32_exp['Expansion Manhattan']).mean().round(4), 100*(results32_exp[col]/results32_exp['Expansion Manhattan']).std().round(4), 100*(resultsresized_exp[col]/resultsresized_exp['Expansion Manhattan']).mean().round(4), 100*(resultsresized_exp[col]/resultsresized_exp['Expansion Manhattan']).std().round(4))\n",
    "\n",
    "results32_time = results32_on_32.filter(like='Time')\n",
    "resultsresized_time = resultsresized_on_32.filter(like='Time')\n",
    "\n",
    "print()\n",
    "for col in results32_time.columns:\n",
    "    if \"Inference\" in col:\n",
    "        print(col, (results32_time[col]).mean().round(2), (results32_time[col]).std().round(2), (resultsresized_time[col]).mean().round(2), (resultsresized_time[col]).std().round(2))\n",
    "    else:\n",
    "        if \"PPM\" in col and \"CF\" in col:\n",
    "            print(col, (results32_time[col]+results32_on_32['Run Time Inference CF']+results32_on_32['Run Time Inference PPM']).mean().round(2), (results32_time[col]+results32_on_32['Run Time Inference CF']+results32_on_32['Run Time Inference PPM']).std().round(2), (resultsresized_time[col]+resultsresized_on_32['Run Time Inference CF']+resultsresized_on_32['Run Time Inference PPM']).mean().round(2), (resultsresized_time[col]+resultsresized_on_32['Run Time Inference CF']+resultsresized_on_32['Run Time Inference PPM']).std().round(2))\n",
    "        elif \"PPM\" in col:\n",
    "            print(col, (results32_time[col]+results32_on_32['Run Time Inference PPM']).mean().round(2), (results32_time[col]+results32_on_32['Run Time Inference PPM']).std().round(2), (resultsresized_time[col]+resultsresized_on_32['Run Time Inference PPM']).mean().round(2), (resultsresized_time[col]+resultsresized_on_32['Run Time Inference PPM']).std().round(2))\n",
    "        elif \"CF\" in col:\n",
    "            print(col, (results32_time[col]+results32_on_32['Run Time Inference CF']).mean().round(2), (results32_time[col]+results32_on_32['Run Time Inference CF']).std().round(2), (resultsresized_time[col]+resultsresized_on_32['Run Time Inference CF']).mean().round(2), (resultsresized_time[col]+resultsresized_on_32['Run Time Inference CF']).std().round(2))\n",
    "        else:\n",
    "            print(col, (results32_time[col]).mean().round(2), (results32_time[col]).std().round(2), (resultsresized_time[col]).mean().round(2), (resultsresized_time[col]).std().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results32_on_32 = pd.read_csv('no_w_espoir_final_32.csv') #no_w_espoir_final_32\n",
    "resultsresized_on_32 = pd.read_csv('no_w_espoir_final_resized.csv')\n",
    "# print number of instances\n",
    "print(results32_on_32.shape[0], resultsresized_on_32.shape[0])\n",
    "\n",
    "results32_on_32 = get_results_instance_complexity_more_than(results32_on_32, 1.05)\n",
    "resultsresized_on_32 = get_results_instance_complexity_more_than(resultsresized_on_32, 1.05)\n",
    "\n",
    "print(results32_on_32.shape[0], resultsresized_on_32.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results32_on_32 = pd.read_csv('no_w_espoir_final_32.csv') #no_w_espoir_final_32\n",
    "resultsresized_on_32 = pd.read_csv('no_w_espoir_final_resized.csv')\n",
    "\n",
    "results32_on_32 = get_results_instance_complexity_more_than(results32_on_32, 1.05)\n",
    "resultsresized_on_32 = get_results_instance_complexity_more_than(resultsresized_on_32, 1.05)\n",
    "\n",
    "# print mean and std of the optimal F value\n",
    "results32_opti = results32_on_32.filter(like='Optimal F')\n",
    "resultsresized_opti = resultsresized_on_32.filter(like='Optimal F')\n",
    "\n",
    "results32_path = results32_on_32.filter(like='Path L')\n",
    "resultsresized_path = resultsresized_on_32.filter(like='Path L')\n",
    "\n",
    "results32_exp = results32_on_32.filter(like='Exp')\n",
    "resultsresized_exp = resultsresized_on_32.filter(like='Exp')\n",
    "\n",
    "for col in results32_opti.columns:\n",
    "    print(col, results32_opti[col].mean().round(2), resultsresized_opti[col].mean().round(2))\n",
    "\n",
    "print()\n",
    "for col in results32_path.columns:\n",
    "    print(col, 100*(results32_path[col]/results32_path['Ground Truth Path Length']).mean().round(4), 100*(results32_path[col]/results32_path['Ground Truth Path Length']).std().round(4), 100*(resultsresized_path[col]/resultsresized_path['Ground Truth Path Length']).mean().round(4), 100*(resultsresized_path[col]/resultsresized_path['Ground Truth Path Length']).std().round(4))\n",
    "\n",
    "print()\n",
    "for col in results32_exp.columns:\n",
    "    if col == 'Expansion Manhattan' or col == 'Expansion GT':\n",
    "        continue\n",
    "    print(col, 100*(results32_exp[col]/results32_exp['Expansion Manhattan']).mean().round(4), 100*(results32_exp[col]/results32_exp['Expansion Manhattan']).std().round(4), 100*(resultsresized_exp[col]/resultsresized_exp['Expansion Manhattan']).mean().round(4), 100*(resultsresized_exp[col]/resultsresized_exp['Expansion Manhattan']).std().round(4))\n",
    "\n",
    "results32_time = results32_on_32.filter(like='Time')\n",
    "resultsresized_time = resultsresized_on_32.filter(like='Time')\n",
    "\n",
    "print()\n",
    "for col in results32_time.columns:\n",
    "    if \"Inference\" in col:\n",
    "        print(col, (results32_time[col]).mean().round(2), (results32_time[col]).std().round(2), (resultsresized_time[col]).mean().round(2), (resultsresized_time[col]).std().round(2))\n",
    "    else:\n",
    "        if \"PPM\" in col and \"CF\" in col:\n",
    "            print(col, (results32_time[col]+results32_on_32['Run Time Inference CF']+results32_on_32['Run Time Inference PPM']).mean().round(2), (results32_time[col]+results32_on_32['Run Time Inference CF']+results32_on_32['Run Time Inference PPM']).std().round(2), (resultsresized_time[col]+resultsresized_on_32['Run Time Inference CF']+resultsresized_on_32['Run Time Inference PPM']).mean().round(2), (resultsresized_time[col]+resultsresized_on_32['Run Time Inference CF']+resultsresized_on_32['Run Time Inference PPM']).std().round(2))\n",
    "        elif \"PPM\" in col:\n",
    "            print(col, (results32_time[col]+results32_on_32['Run Time Inference PPM']).mean().round(2), (results32_time[col]+results32_on_32['Run Time Inference PPM']).std().round(2), (resultsresized_time[col]+resultsresized_on_32['Run Time Inference PPM']).mean().round(2), (resultsresized_time[col]+resultsresized_on_32['Run Time Inference PPM']).std().round(2))\n",
    "        elif \"CF\" in col:\n",
    "            print(col, (results32_time[col]+results32_on_32['Run Time Inference CF']).mean().round(2), (results32_time[col]+results32_on_32['Run Time Inference CF']).std().round(2), (resultsresized_time[col]+resultsresized_on_32['Run Time Inference CF']).mean().round(2), (resultsresized_time[col]+resultsresized_on_32['Run Time Inference CF']).std().round(2))\n",
    "        else:\n",
    "            print(col, (results32_time[col]).mean().round(2), (results32_time[col]).std().round(2), (resultsresized_time[col]).mean().round(2), (resultsresized_time[col]).std().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results32_on_resized = pd.read_csv('32_espoir_results_on_new_dataset.csv')\n",
    "resultsresized_on_resized = pd.read_csv('resized_espoir_results_on_new_dataset.csv')\n",
    "\n",
    "results32_on_resized = get_results_instance_complexity_more_than(results32_on_resized, 1.05)\n",
    "resultsresized_on_resized = get_results_instance_complexity_more_than(resultsresized_on_resized, 1.05)\n",
    "\n",
    "results32_opti = results32_on_resized.filter(like='Optimal F')\n",
    "resultsresized_opti = resultsresized_on_resized.filter(like='Optimal F')\n",
    "\n",
    "results32_path = results32_on_resized.filter(like='Path L')\n",
    "resultsresized_path = resultsresized_on_resized.filter(like='Path L')\n",
    "\n",
    "results32_exp = results32_on_resized.filter(like='Exp')\n",
    "resultsresized_exp = resultsresized_on_resized.filter(like='Exp')\n",
    "\n",
    "for col in results32_opti.columns:\n",
    "    print(col, results32_opti[col].mean().round(2), resultsresized_opti[col].mean().round(2))\n",
    "\n",
    "print()\n",
    "for col in results32_path.columns:\n",
    "    print(col, 100*(results32_path[col]/results32_path['Ground Truth Path Length']).mean().round(4), 100*(results32_path[col]/results32_path['Ground Truth Path Length']).std().round(4), 100*(resultsresized_path[col]/resultsresized_path['Ground Truth Path Length']).mean().round(4), 100*(resultsresized_path[col]/resultsresized_path['Ground Truth Path Length']).std().round(4))\n",
    "\n",
    "print()\n",
    "for col in results32_exp.columns:\n",
    "    if col == 'Expansion Manhattan' or col == 'Expansion GT':\n",
    "        continue\n",
    "    print(col, 100*(results32_exp[col]/results32_exp['Expansion Manhattan']).mean().round(4), 100*(results32_exp[col]/results32_exp['Expansion Manhattan']).std().round(4), 100*(resultsresized_exp[col]/resultsresized_exp['Expansion Manhattan']).mean().round(4), 100*(resultsresized_exp[col]/resultsresized_exp['Expansion Manhattan']).std().round(4))\n",
    "\n",
    "results32_time = results32_on_resized.filter(like='Time')\n",
    "resultsresized_time = resultsresized_on_resized.filter(like='Time')\n",
    "\n",
    "print()\n",
    "for col in results32_time.columns:\n",
    "    if \"Inference\" in col:\n",
    "        print(col, (results32_time[col]).mean().round(2), (results32_time[col]).std().round(2), (resultsresized_time[col]).mean().round(2), (resultsresized_time[col]).std().round(2))\n",
    "    else:\n",
    "        if \"PPM\" in col and \"CF\" in col:\n",
    "            print(col, (results32_time[col]+results32_on_32['Run Time Inference CF']+results32_on_32['Run Time Inference PPM']).mean().round(2), (results32_time[col]+results32_on_32['Run Time Inference CF']+results32_on_32['Run Time Inference PPM']).std().round(2), (resultsresized_time[col]+resultsresized_on_32['Run Time Inference CF']+resultsresized_on_32['Run Time Inference PPM']).mean().round(2), (resultsresized_time[col]+resultsresized_on_32['Run Time Inference CF']+resultsresized_on_32['Run Time Inference PPM']).std().round(2))\n",
    "        elif \"PPM\" in col:\n",
    "            print(col, (results32_time[col]+results32_on_32['Run Time Inference PPM']).mean().round(2), (results32_time[col]+results32_on_32['Run Time Inference PPM']).std().round(2), (resultsresized_time[col]+resultsresized_on_32['Run Time Inference PPM']).mean().round(2), (resultsresized_time[col]+resultsresized_on_32['Run Time Inference PPM']).std().round(2))\n",
    "        elif \"CF\" in col:\n",
    "            print(col, (results32_time[col]+results32_on_32['Run Time Inference CF']).mean().round(2), (results32_time[col]+results32_on_32['Run Time Inference CF']).std().round(2), (resultsresized_time[col]+resultsresized_on_32['Run Time Inference CF']).mean().round(2), (resultsresized_time[col]+resultsresized_on_32['Run Time Inference CF']).std().round(2))\n",
    "        else:\n",
    "            print(col, (results32_time[col]).mean().round(2), (results32_time[col]).std().round(2), (resultsresized_time[col]).mean().round(2), (resultsresized_time[col]).std().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results32_on_resized = pd.read_csv('no_w_32_espoir_results_on_new_dataset.csv')\n",
    "resultsresized_on_resized = pd.read_csv('no_w_resized_espoir_results_on_new_dataset.csv') #no_w_\n",
    "\n",
    "# PRINT NUMBER OF INSTANCES IN BOTH DATASETS\n",
    "print(results32_on_resized.shape[0], resultsresized_on_resized.shape[0])\n",
    "\n",
    "results32_on_resized = get_results_instance_complexity_more_than(results32_on_resized, 1.05)\n",
    "resultsresized_on_resized = get_results_instance_complexity_more_than(resultsresized_on_resized, 1.05)\n",
    "\n",
    "# PRINT NUMBER OF INSTANCES IN BOTH DATASETS\n",
    "print(results32_on_resized.shape[0], resultsresized_on_resized.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results32_on_resized = pd.read_csv('no_w_32_espoir_results_on_new_dataset.csv')\n",
    "resultsresized_on_resized = pd.read_csv('no_w_resized_espoir_results_on_new_dataset.csv') #no_w_\n",
    "\n",
    "# PRINT NUMBER OF INSTANCES IN BOTH DATASETS\n",
    "print(results32_on_resized.shape[0], resultsresized_on_resized.shape[0])\n",
    "\n",
    "results32_on_resized = get_results_instance_complexity_more_than(results32_on_resized, 1.05)\n",
    "resultsresized_on_resized = get_results_instance_complexity_more_than(resultsresized_on_resized, 1.05)\n",
    "\n",
    "# PRINT NUMBER OF INSTANCES IN BOTH DATASETS\n",
    "print(results32_on_resized.shape[0], resultsresized_on_resized.shape[0])\n",
    "\n",
    "results32_opti = results32_on_resized.filter(like='Optimal F')\n",
    "resultsresized_opti = resultsresized_on_resized.filter(like='Optimal F')\n",
    "\n",
    "results32_path = results32_on_resized.filter(like='Path L')\n",
    "resultsresized_path = resultsresized_on_resized.filter(like='Path L')\n",
    "\n",
    "results32_exp = results32_on_resized.filter(like='Exp')\n",
    "resultsresized_exp = resultsresized_on_resized.filter(like='Exp')\n",
    "\n",
    "for col in results32_opti.columns:\n",
    "    print(col, results32_opti[col].mean().round(2), resultsresized_opti[col].mean().round(2))\n",
    "\n",
    "print()\n",
    "for col in results32_path.columns:\n",
    "    print(col, 100*(results32_path[col]/results32_path['Ground Truth Path Length']).mean().round(4), 100*(results32_path[col]/results32_path['Ground Truth Path Length']).std().round(4), 100*(resultsresized_path[col]/resultsresized_path['Ground Truth Path Length']).mean().round(4), 100*(resultsresized_path[col]/resultsresized_path['Ground Truth Path Length']).std().round(4))\n",
    "\n",
    "print()\n",
    "for col in results32_exp.columns:\n",
    "    if col == 'Expansion Manhattan' or col == 'Expansion GT':\n",
    "        continue\n",
    "    print(col, 100*(results32_exp[col]/results32_exp['Expansion Manhattan']).mean().round(4), 100*(results32_exp[col]/results32_exp['Expansion Manhattan']).std().round(4), 100*(resultsresized_exp[col]/resultsresized_exp['Expansion Manhattan']).mean().round(4), 100*(resultsresized_exp[col]/resultsresized_exp['Expansion Manhattan']).std().round(4))\n",
    "\n",
    "results32_time = results32_on_resized.filter(like='Time')\n",
    "resultsresized_time = resultsresized_on_resized.filter(like='Time')\n",
    "\n",
    "print()\n",
    "for col in results32_time.columns:\n",
    "    if \"Inference\" in col:\n",
    "        print(col, (results32_time[col]).mean().round(2), (results32_time[col]).std().round(2), (resultsresized_time[col]).mean().round(2), (resultsresized_time[col]).std().round(2))\n",
    "    else:\n",
    "        if \"PPM\" in col and \"CF\" in col:\n",
    "            print(col, (results32_time[col]+results32_on_resized['Run Time Inference CF']+results32_on_resized['Run Time Inference PPM']).mean().round(2), (results32_time[col]+results32_on_resized['Run Time Inference CF']+results32_on_resized['Run Time Inference PPM']).std().round(2), (resultsresized_time[col]+resultsresized_on_resized['Run Time Inference CF']+resultsresized_on_resized['Run Time Inference PPM']).mean().round(2), (resultsresized_time[col]+resultsresized_on_resized['Run Time Inference CF']+resultsresized_on_resized['Run Time Inference PPM']).std().round(2))\n",
    "        elif \"PPM\" in col:\n",
    "            print(col, (results32_time[col]+results32_on_resized['Run Time Inference PPM']).mean().round(2), (results32_time[col]+results32_on_resized['Run Time Inference PPM']).std().round(2), (resultsresized_time[col]+resultsresized_on_resized['Run Time Inference PPM']).mean().round(2), (resultsresized_time[col]+resultsresized_on_resized['Run Time Inference PPM']).std().round(2))\n",
    "        elif \"CF\" in col:\n",
    "            print(col, (results32_time[col]+results32_on_resized['Run Time Inference CF']).mean().round(2), (results32_time[col]+results32_on_resized['Run Time Inference CF']).std().round(2), (resultsresized_time[col]+resultsresized_on_resized['Run Time Inference CF']).mean().round(2), (resultsresized_time[col]+resultsresized_on_resized['Run Time Inference CF']).std().round(2))\n",
    "        else:\n",
    "            print(col, (results32_time[col]).mean().round(2), (results32_time[col]).std().round(2), (resultsresized_time[col]).mean().round(2), (resultsresized_time[col]).std().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results32_on_oob = pd.read_csv('32_espoir_out_of_distrib.csv')\n",
    "resultsresized_on_oob = pd.read_csv('resized_espoir_out_of_distrib.csv')\n",
    "\n",
    "results32_on_oob = get_results_instance_complexity_more_than(results32_on_oob, 1.05)\n",
    "resultsresized_on_oob = get_results_instance_complexity_more_than(resultsresized_on_oob, 1.05)\n",
    "\n",
    "results32_opti = results32_on_oob.filter(like='Optimal F')\n",
    "resultsresized_opti = resultsresized_on_oob.filter(like='Optimal F')\n",
    "\n",
    "results32_path = results32_on_oob.filter(like='Path L')\n",
    "resultsresized_path = resultsresized_on_oob.filter(like='Path L')\n",
    "\n",
    "results32_exp = results32_on_oob.filter(like='Exp')\n",
    "resultsresized_exp = resultsresized_on_oob.filter(like='Exp')\n",
    "\n",
    "for col in results32_opti.columns:\n",
    "    print(col, results32_opti[col].mean().round(2), resultsresized_opti[col].mean().round(2))\n",
    "\n",
    "print()\n",
    "for col in results32_path.columns:\n",
    "    print(col, 100*(results32_path[col]/results32_path['Ground Truth Path Length']).mean().round(4), 100*(results32_path[col]/results32_path['Ground Truth Path Length']).std().round(4), 100*(resultsresized_path[col]/resultsresized_path['Ground Truth Path Length']).mean().round(4), 100*(resultsresized_path[col]/resultsresized_path['Ground Truth Path Length']).std().round(4))\n",
    "\n",
    "print()\n",
    "for col in results32_exp.columns:\n",
    "    if col == 'Expansion Manhattan' or col == 'Expansion GT':\n",
    "        continue\n",
    "    print(col, 100*(results32_exp[col]/results32_exp['Expansion Manhattan']).mean().round(4), 100*(results32_exp[col]/results32_exp['Expansion Manhattan']).std().round(4), 100*(resultsresized_exp[col]/resultsresized_exp['Expansion Manhattan']).mean().round(4), 100*(resultsresized_exp[col]/resultsresized_exp['Expansion Manhattan']).std().round(4))\n",
    "\n",
    "results32_time = results32_on_oob.filter(like='Time')\n",
    "resultsresized_time = resultsresized_on_oob.filter(like='Time')\n",
    "\n",
    "print()\n",
    "for col in results32_time.columns:\n",
    "    if \"Inference\" in col:\n",
    "        print(col, (results32_time[col]).mean().round(2), (results32_time[col]).std().round(2), (resultsresized_time[col]).mean().round(2), (resultsresized_time[col]).std().round(2))\n",
    "    else:\n",
    "        if \"PPM\" in col and \"CF\" in col:\n",
    "            print(col, (results32_time[col]+results32_on_32['Run Time Inference CF']+results32_on_32['Run Time Inference PPM']).mean().round(2), (results32_time[col]+results32_on_32['Run Time Inference CF']+results32_on_32['Run Time Inference PPM']).std().round(2), (resultsresized_time[col]+resultsresized_on_32['Run Time Inference CF']+resultsresized_on_32['Run Time Inference PPM']).mean().round(2), (resultsresized_time[col]+resultsresized_on_32['Run Time Inference CF']+resultsresized_on_32['Run Time Inference PPM']).std().round(2))\n",
    "        elif \"PPM\" in col:\n",
    "            print(col, (results32_time[col]+results32_on_32['Run Time Inference PPM']).mean().round(2), (results32_time[col]+results32_on_32['Run Time Inference PPM']).std().round(2), (resultsresized_time[col]+resultsresized_on_32['Run Time Inference PPM']).mean().round(2), (resultsresized_time[col]+resultsresized_on_32['Run Time Inference PPM']).std().round(2))\n",
    "        elif \"CF\" in col:\n",
    "            print(col, (results32_time[col]+results32_on_32['Run Time Inference CF']).mean().round(2), (results32_time[col]+results32_on_32['Run Time Inference CF']).std().round(2), (resultsresized_time[col]+resultsresized_on_32['Run Time Inference CF']).mean().round(2), (resultsresized_time[col]+resultsresized_on_32['Run Time Inference CF']).std().round(2))\n",
    "        else:\n",
    "            print(col, (results32_time[col]).mean().round(2), (results32_time[col]).std().round(2), (resultsresized_time[col]).mean().round(2), (resultsresized_time[col]).std().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results32_on_oob = pd.read_csv('32_espoir_out_of_distrib_NON_resized.csv') # TODO\n",
    "resultsresized_on_oob = pd.read_csv('resized_espoir_out_of_distrib_NON_resized.csv')\n",
    "\n",
    "results32_on_oob = get_results_instance_complexity_more_than(results32_on_oob, 1.05)\n",
    "resultsresized_on_oob = get_results_instance_complexity_more_than(resultsresized_on_oob, 1.05)\n",
    "\n",
    "results32_opti = results32_on_oob.filter(like='Optimal F')\n",
    "resultsresized_opti = resultsresized_on_oob.filter(like='Optimal F')\n",
    "\n",
    "results32_path = results32_on_oob.filter(like='Path L')\n",
    "resultsresized_path = resultsresized_on_oob.filter(like='Path L')\n",
    "\n",
    "results32_exp = results32_on_oob.filter(like='Exp')\n",
    "resultsresized_exp = resultsresized_on_oob.filter(like='Exp')\n",
    "\n",
    "for col in results32_opti.columns:\n",
    "    print(col, results32_opti[col].mean().round(2), resultsresized_opti[col].mean().round(2))\n",
    "\n",
    "print()\n",
    "for col in results32_path.columns:\n",
    "    print(col, 100*(results32_path[col]/results32_path['Ground Truth Path Length']).mean().round(4), 100*(results32_path[col]/results32_path['Ground Truth Path Length']).std().round(4), 100*(resultsresized_path[col]/resultsresized_path['Ground Truth Path Length']).mean().round(4), 100*(resultsresized_path[col]/resultsresized_path['Ground Truth Path Length']).std().round(4))\n",
    "\n",
    "print()\n",
    "for col in results32_exp.columns:\n",
    "    if col == 'Expansion Manhattan' or col == 'Expansion GT':\n",
    "        continue\n",
    "    print(col, 100*(results32_exp[col]/results32_exp['Expansion Manhattan']).mean().round(4), 100*(results32_exp[col]/results32_exp['Expansion Manhattan']).std().round(4), 100*(resultsresized_exp[col]/resultsresized_exp['Expansion Manhattan']).mean().round(4), 100*(resultsresized_exp[col]/resultsresized_exp['Expansion Manhattan']).std().round(4))\n",
    "\n",
    "results32_time = results32_on_oob.filter(like='Time')\n",
    "resultsresized_time = resultsresized_on_oob.filter(like='Time')\n",
    "\n",
    "print()\n",
    "for col in results32_time.columns:\n",
    "    if \"Inference\" in col:\n",
    "        print(col, (results32_time[col]).mean().round(2), (results32_time[col]).std().round(2), (resultsresized_time[col]).mean().round(2), (resultsresized_time[col]).std().round(2))\n",
    "    else:\n",
    "        if \"PPM\" in col and \"CF\" in col:\n",
    "            print(col, (results32_time[col]+results32_on_oob['Run Time Inference CF']+results32_on_oob['Run Time Inference PPM']).mean().round(2), (results32_time[col]+results32_on_oob['Run Time Inference CF']+results32_on_oob['Run Time Inference PPM']).std().round(2), (resultsresized_time[col]+resultsresized_on_oob['Run Time Inference CF']+resultsresized_on_oob['Run Time Inference PPM']).mean().round(2), (resultsresized_time[col]+resultsresized_on_oob['Run Time Inference CF']+resultsresized_on_oob['Run Time Inference PPM']).std().round(2))\n",
    "        elif \"PPM\" in col:\n",
    "            print(col, (results32_time[col]+results32_on_oob['Run Time Inference PPM']).mean().round(2), (results32_time[col]+results32_on_oob['Run Time Inference PPM']).std().round(2), (resultsresized_time[col]+resultsresized_on_oob['Run Time Inference PPM']).mean().round(2), (resultsresized_time[col]+resultsresized_on_oob['Run Time Inference PPM']).std().round(2))\n",
    "        elif \"CF\" in col:\n",
    "            print(col, (results32_time[col]+results32_on_oob['Run Time Inference CF']).mean().round(2), (results32_time[col]+results32_on_oob['Run Time Inference CF']).std().round(2), (resultsresized_time[col]+resultsresized_on_oob['Run Time Inference CF']).mean().round(2), (resultsresized_time[col]+resultsresized_on_oob['Run Time Inference CF']).std().round(2))\n",
    "        else:\n",
    "            print(col, (results32_time[col]).mean().round(2), (results32_time[col]).std().round(2), (resultsresized_time[col]).mean().round(2), (resultsresized_time[col]).std().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results32_on_oob = pd.read_csv('no_w_32_espoir_out_of_distrib_NON_resized.csv') # TODO\n",
    "resultsresized_on_oob = pd.read_csv('no_w_resized_espoir_out_of_distrib_NON_resized.csv') # no_w_\n",
    "\n",
    "print(results32_on_oob.shape[0], resultsresized_on_oob.shape[0])\n",
    "\n",
    "results32_on_oob = get_results_instance_complexity_more_than(results32_on_oob, 1.05)\n",
    "resultsresized_on_oob = get_results_instance_complexity_more_than(resultsresized_on_oob, 1.05)\n",
    "\n",
    "print(results32_on_oob.shape[0], resultsresized_on_oob.shape[0])\n",
    "\n",
    "results32_opti = results32_on_oob.filter(like='Optimal F')\n",
    "resultsresized_opti = resultsresized_on_oob.filter(like='Optimal F')\n",
    "\n",
    "results32_path = results32_on_oob.filter(like='Path L')\n",
    "resultsresized_path = resultsresized_on_oob.filter(like='Path L')\n",
    "\n",
    "results32_exp = results32_on_oob.filter(like='Exp')\n",
    "resultsresized_exp = resultsresized_on_oob.filter(like='Exp')\n",
    "\n",
    "for col in results32_opti.columns:\n",
    "    print(col, results32_opti[col].mean().round(2), resultsresized_opti[col].mean().round(2))\n",
    "\n",
    "print()\n",
    "for col in results32_path.columns:\n",
    "    print(col, 100*(results32_path[col]/results32_path['Ground Truth Path Length']).mean().round(4), 100*(results32_path[col]/results32_path['Ground Truth Path Length']).std().round(4), 100*(resultsresized_path[col]/resultsresized_path['Ground Truth Path Length']).mean().round(4), 100*(resultsresized_path[col]/resultsresized_path['Ground Truth Path Length']).std().round(4))\n",
    "\n",
    "print()\n",
    "for col in results32_exp.columns:\n",
    "    if col == 'Expansion Manhattan' or col == 'Expansion GT':\n",
    "        continue\n",
    "    print(col, 100*(results32_exp[col]/results32_exp['Expansion Manhattan']).mean().round(4), 100*(results32_exp[col]/results32_exp['Expansion Manhattan']).std().round(4), 100*(resultsresized_exp[col]/resultsresized_exp['Expansion Manhattan']).mean().round(4), 100*(resultsresized_exp[col]/resultsresized_exp['Expansion Manhattan']).std().round(4))\n",
    "\n",
    "results32_time = results32_on_oob.filter(like='Time')\n",
    "resultsresized_time = resultsresized_on_oob.filter(like='Time')\n",
    "\n",
    "print()\n",
    "for col in results32_time.columns:\n",
    "    if \"Inference\" in col:\n",
    "        print(col, (results32_time[col]).mean().round(2), (results32_time[col]).std().round(2), (resultsresized_time[col]).mean().round(2), (resultsresized_time[col]).std().round(2))\n",
    "    else:\n",
    "        if \"PPM\" in col and \"CF\" in col:\n",
    "            print(col, (results32_time[col]+results32_on_oob['Run Time Inference CF']+results32_on_oob['Run Time Inference PPM']).mean().round(2), (results32_time[col]+results32_on_oob['Run Time Inference CF']+results32_on_oob['Run Time Inference PPM']).std().round(2), (resultsresized_time[col]+resultsresized_on_oob['Run Time Inference CF']+resultsresized_on_oob['Run Time Inference PPM']).mean().round(2), (resultsresized_time[col]+resultsresized_on_oob['Run Time Inference CF']+resultsresized_on_oob['Run Time Inference PPM']).std().round(2))\n",
    "        elif \"PPM\" in col:\n",
    "            print(col, (results32_time[col]+results32_on_oob['Run Time Inference PPM']).mean().round(2), (results32_time[col]+results32_on_oob['Run Time Inference PPM']).std().round(2), (resultsresized_time[col]+resultsresized_on_oob['Run Time Inference PPM']).mean().round(2), (resultsresized_time[col]+resultsresized_on_oob['Run Time Inference PPM']).std().round(2))\n",
    "        elif \"CF\" in col:\n",
    "            print(col, (results32_time[col]+results32_on_oob['Run Time Inference CF']).mean().round(2), (results32_time[col]+results32_on_oob['Run Time Inference CF']).std().round(2), (resultsresized_time[col]+resultsresized_on_oob['Run Time Inference CF']).mean().round(2), (resultsresized_time[col]+resultsresized_on_oob['Run Time Inference CF']).std().round(2))\n",
    "        else:\n",
    "            print(col, (results32_time[col]).mean().round(2), (results32_time[col]).std().round(2), (resultsresized_time[col]).mean().round(2), (resultsresized_time[col]).std().round(2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
